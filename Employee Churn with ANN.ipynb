{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def8b2ec-1328-41d9-9aca-143b2cced8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.75.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/331.9 MB 5.0 MB/s eta 0:01:06\n",
      "   ---------------------------------------- 3.9/331.9 MB 8.7 MB/s eta 0:00:38\n",
      "   ---------------------------------------- 3.9/331.9 MB 8.7 MB/s eta 0:00:38\n",
      "    --------------------------------------- 5.2/331.9 MB 6.0 MB/s eta 0:00:55\n",
      "    --------------------------------------- 5.2/331.9 MB 6.0 MB/s eta 0:00:55\n",
      "    --------------------------------------- 5.2/331.9 MB 6.0 MB/s eta 0:00:55\n",
      "    --------------------------------------- 5.5/331.9 MB 3.7 MB/s eta 0:01:29\n",
      "    --------------------------------------- 6.6/331.9 MB 3.8 MB/s eta 0:01:26\n",
      "    --------------------------------------- 7.9/331.9 MB 4.0 MB/s eta 0:01:21\n",
      "   - -------------------------------------- 8.9/331.9 MB 4.2 MB/s eta 0:01:17\n",
      "   - -------------------------------------- 9.4/331.9 MB 4.3 MB/s eta 0:01:16\n",
      "   - -------------------------------------- 9.7/331.9 MB 3.9 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 10.7/331.9 MB 3.9 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 11.5/331.9 MB 3.8 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 11.5/331.9 MB 3.8 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 12.6/331.9 MB 3.8 MB/s eta 0:01:26\n",
      "   - -------------------------------------- 13.6/331.9 MB 3.8 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 14.4/331.9 MB 3.8 MB/s eta 0:01:25\n",
      "   - -------------------------------------- 14.7/331.9 MB 3.8 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 15.2/331.9 MB 3.6 MB/s eta 0:01:29\n",
      "   - -------------------------------------- 15.5/331.9 MB 3.6 MB/s eta 0:01:29\n",
      "   - -------------------------------------- 16.0/331.9 MB 3.5 MB/s eta 0:01:32\n",
      "   - -------------------------------------- 16.5/331.9 MB 3.4 MB/s eta 0:01:33\n",
      "   -- ------------------------------------- 17.0/331.9 MB 3.4 MB/s eta 0:01:34\n",
      "   -- ------------------------------------- 17.6/331.9 MB 3.3 MB/s eta 0:01:35\n",
      "   -- ------------------------------------- 17.8/331.9 MB 3.3 MB/s eta 0:01:36\n",
      "   -- ------------------------------------- 18.4/331.9 MB 3.3 MB/s eta 0:01:37\n",
      "   -- ------------------------------------- 18.9/331.9 MB 3.2 MB/s eta 0:01:37\n",
      "   -- ------------------------------------- 19.4/331.9 MB 3.2 MB/s eta 0:01:38\n",
      "   -- ------------------------------------- 19.9/331.9 MB 3.2 MB/s eta 0:01:39\n",
      "   -- ------------------------------------- 20.4/331.9 MB 3.1 MB/s eta 0:01:40\n",
      "   -- ------------------------------------- 21.0/331.9 MB 3.1 MB/s eta 0:01:40\n",
      "   -- ------------------------------------- 21.5/331.9 MB 3.1 MB/s eta 0:01:41\n",
      "   -- ------------------------------------- 21.8/331.9 MB 3.1 MB/s eta 0:01:41\n",
      "   -- ------------------------------------- 22.3/331.9 MB 3.0 MB/s eta 0:01:43\n",
      "   -- ------------------------------------- 22.8/331.9 MB 3.0 MB/s eta 0:01:43\n",
      "   -- ------------------------------------- 23.3/331.9 MB 3.0 MB/s eta 0:01:44\n",
      "   -- ------------------------------------- 23.9/331.9 MB 3.0 MB/s eta 0:01:44\n",
      "   -- ------------------------------------- 24.4/331.9 MB 3.0 MB/s eta 0:01:44\n",
      "   --- ------------------------------------ 24.9/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 25.4/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 26.0/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 26.5/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 27.0/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 27.5/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 28.0/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 28.6/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 29.1/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 29.9/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 30.4/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 30.9/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 31.5/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 32.0/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 32.5/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   --- ------------------------------------ 33.0/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 33.6/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 34.3/331.9 MB 2.9 MB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 34.9/331.9 MB 2.9 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 35.7/331.9 MB 2.9 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 36.2/331.9 MB 2.9 MB/s eta 0:01:44\n",
      "   ---- ----------------------------------- 37.0/331.9 MB 2.9 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 37.5/331.9 MB 2.9 MB/s eta 0:01:43\n",
      "   ---- ----------------------------------- 38.3/331.9 MB 2.9 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 38.8/331.9 MB 2.9 MB/s eta 0:01:42\n",
      "   ---- ----------------------------------- 39.6/331.9 MB 2.9 MB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 40.4/331.9 MB 2.9 MB/s eta 0:01:41\n",
      "   ---- ----------------------------------- 41.2/331.9 MB 2.9 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 41.9/331.9 MB 2.9 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 42.7/331.9 MB 2.9 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 43.5/331.9 MB 3.0 MB/s eta 0:01:38\n",
      "   ----- ---------------------------------- 44.3/331.9 MB 3.0 MB/s eta 0:01:38\n",
      "   ----- ---------------------------------- 44.8/331.9 MB 3.0 MB/s eta 0:01:38\n",
      "   ----- ---------------------------------- 45.9/331.9 MB 3.0 MB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 46.1/331.9 MB 3.0 MB/s eta 0:01:36\n",
      "   ----- ---------------------------------- 46.4/331.9 MB 2.9 MB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 46.4/331.9 MB 2.9 MB/s eta 0:01:37\n",
      "   ----- ---------------------------------- 46.7/331.9 MB 2.9 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 46.7/331.9 MB 2.9 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 46.9/331.9 MB 2.8 MB/s eta 0:01:41\n",
      "   ----- ---------------------------------- 47.2/331.9 MB 2.8 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 47.4/331.9 MB 2.8 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 47.7/331.9 MB 2.8 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 47.7/331.9 MB 2.8 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 48.0/331.9 MB 2.7 MB/s eta 0:01:45\n",
      "   ----- ---------------------------------- 48.0/331.9 MB 2.7 MB/s eta 0:01:45\n",
      "   ----- ---------------------------------- 48.0/331.9 MB 2.7 MB/s eta 0:01:45\n",
      "   ----- ---------------------------------- 48.2/331.9 MB 2.6 MB/s eta 0:01:48\n",
      "   ----- ---------------------------------- 48.2/331.9 MB 2.6 MB/s eta 0:01:48\n",
      "   ----- ---------------------------------- 48.5/331.9 MB 2.6 MB/s eta 0:01:50\n",
      "   ----- ---------------------------------- 48.5/331.9 MB 2.6 MB/s eta 0:01:50\n",
      "   ----- ---------------------------------- 48.8/331.9 MB 2.5 MB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 48.8/331.9 MB 2.5 MB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 48.8/331.9 MB 2.5 MB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 48.8/331.9 MB 2.5 MB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 48.8/331.9 MB 2.5 MB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 49.0/331.9 MB 2.4 MB/s eta 0:01:57\n",
      "   ----- ---------------------------------- 49.0/331.9 MB 2.4 MB/s eta 0:01:57\n",
      "   ----- ---------------------------------- 49.3/331.9 MB 2.4 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 49.5/331.9 MB 2.4 MB/s eta 0:01:59\n",
      "   ----- ---------------------------------- 49.5/331.9 MB 2.4 MB/s eta 0:01:59\n",
      "   ------ --------------------------------- 49.8/331.9 MB 2.4 MB/s eta 0:02:00\n",
      "   ------ --------------------------------- 50.1/331.9 MB 2.3 MB/s eta 0:02:01\n",
      "   ------ --------------------------------- 50.3/331.9 MB 2.3 MB/s eta 0:02:01\n",
      "   ------ --------------------------------- 50.6/331.9 MB 2.3 MB/s eta 0:02:02\n",
      "   ------ --------------------------------- 50.9/331.9 MB 2.3 MB/s eta 0:02:02\n",
      "   ------ --------------------------------- 51.1/331.9 MB 2.3 MB/s eta 0:02:02\n",
      "   ------ --------------------------------- 51.4/331.9 MB 2.3 MB/s eta 0:02:03\n",
      "   ------ --------------------------------- 51.6/331.9 MB 2.3 MB/s eta 0:02:03\n",
      "   ------ --------------------------------- 51.6/331.9 MB 2.3 MB/s eta 0:02:03\n",
      "   ------ --------------------------------- 51.9/331.9 MB 2.2 MB/s eta 0:02:05\n",
      "   ------ --------------------------------- 51.9/331.9 MB 2.2 MB/s eta 0:02:05\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.2/331.9 MB 2.2 MB/s eta 0:02:06\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.4/331.9 MB 1.8 MB/s eta 0:02:32\n",
      "   ------ --------------------------------- 52.7/331.9 MB 1.6 MB/s eta 0:02:59\n",
      "   ------ --------------------------------- 52.7/331.9 MB 1.6 MB/s eta 0:02:59\n",
      "   ------ --------------------------------- 52.7/331.9 MB 1.6 MB/s eta 0:02:59\n",
      "   ------ --------------------------------- 52.7/331.9 MB 1.6 MB/s eta 0:02:59\n",
      "   ------ --------------------------------- 53.0/331.9 MB 1.4 MB/s eta 0:03:14\n",
      "   ------ --------------------------------- 53.0/331.9 MB 1.4 MB/s eta 0:03:14\n",
      "   ------ --------------------------------- 53.0/331.9 MB 1.4 MB/s eta 0:03:14\n",
      "   ------ --------------------------------- 53.2/331.9 MB 1.4 MB/s eta 0:03:21\n",
      "   ------ --------------------------------- 53.2/331.9 MB 1.4 MB/s eta 0:03:21\n",
      "   ------ --------------------------------- 53.5/331.9 MB 1.3 MB/s eta 0:03:30\n",
      "   ------ --------------------------------- 53.5/331.9 MB 1.3 MB/s eta 0:03:30\n",
      "   ------ --------------------------------- 53.5/331.9 MB 1.3 MB/s eta 0:03:30\n",
      "   ------ --------------------------------- 53.7/331.9 MB 1.3 MB/s eta 0:03:35\n",
      "   ------ --------------------------------- 53.7/331.9 MB 1.3 MB/s eta 0:03:35\n",
      "   ------ --------------------------------- 54.0/331.9 MB 1.3 MB/s eta 0:03:40\n",
      "   ------ --------------------------------- 54.0/331.9 MB 1.3 MB/s eta 0:03:40\n",
      "   ------ --------------------------------- 54.3/331.9 MB 1.2 MB/s eta 0:03:44\n",
      "   ------ --------------------------------- 54.3/331.9 MB 1.2 MB/s eta 0:03:44\n",
      "   ------ --------------------------------- 54.5/331.9 MB 1.2 MB/s eta 0:03:48\n",
      "   ------ --------------------------------- 54.5/331.9 MB 1.2 MB/s eta 0:03:48\n",
      "   ------ --------------------------------- 54.8/331.9 MB 1.2 MB/s eta 0:03:51\n",
      "   ------ --------------------------------- 55.1/331.9 MB 1.2 MB/s eta 0:03:53\n",
      "   ------ --------------------------------- 55.1/331.9 MB 1.2 MB/s eta 0:03:53\n",
      "   ------ --------------------------------- 55.3/331.9 MB 1.2 MB/s eta 0:03:57\n",
      "   ------ --------------------------------- 55.6/331.9 MB 1.2 MB/s eta 0:03:59\n",
      "   ------ --------------------------------- 55.8/331.9 MB 1.1 MB/s eta 0:04:03\n",
      "   ------ --------------------------------- 56.1/331.9 MB 1.1 MB/s eta 0:04:03\n",
      "   ------ --------------------------------- 56.1/331.9 MB 1.1 MB/s eta 0:04:03\n",
      "   ------ --------------------------------- 56.1/331.9 MB 1.1 MB/s eta 0:04:03\n",
      "   ------ --------------------------------- 56.4/331.9 MB 1.1 MB/s eta 0:04:12\n",
      "   ------ --------------------------------- 56.6/331.9 MB 1.1 MB/s eta 0:04:14\n",
      "   ------ --------------------------------- 56.6/331.9 MB 1.1 MB/s eta 0:04:14\n",
      "   ------ --------------------------------- 56.6/331.9 MB 1.1 MB/s eta 0:04:14\n",
      "   ------ --------------------------------- 56.9/331.9 MB 1.1 MB/s eta 0:04:22\n",
      "   ------ --------------------------------- 56.9/331.9 MB 1.1 MB/s eta 0:04:22\n",
      "   ------ --------------------------------- 56.9/331.9 MB 1.1 MB/s eta 0:04:22\n",
      "   ------ --------------------------------- 57.1/331.9 MB 1.0 MB/s eta 0:04:33\n",
      "   ------ --------------------------------- 57.1/331.9 MB 1.0 MB/s eta 0:04:33\n",
      "   ------ -------------------------------- 57.4/331.9 MB 972.5 kB/s eta 0:04:43\n",
      "   ------ -------------------------------- 57.7/331.9 MB 962.7 kB/s eta 0:04:45\n",
      "   ------ -------------------------------- 57.9/331.9 MB 946.7 kB/s eta 0:04:50\n",
      "   ------ -------------------------------- 57.9/331.9 MB 946.7 kB/s eta 0:04:50\n",
      "   ------ -------------------------------- 57.9/331.9 MB 946.7 kB/s eta 0:04:50\n",
      "   ------ -------------------------------- 58.2/331.9 MB 908.8 kB/s eta 0:05:02\n",
      "   ------ -------------------------------- 58.2/331.9 MB 908.8 kB/s eta 0:05:02\n",
      "   ------ -------------------------------- 58.2/331.9 MB 908.8 kB/s eta 0:05:02\n",
      "   ------ -------------------------------- 58.2/331.9 MB 908.8 kB/s eta 0:05:02\n",
      "   ------ -------------------------------- 58.2/331.9 MB 908.8 kB/s eta 0:05:02\n",
      "   ------ -------------------------------- 58.2/331.9 MB 908.8 kB/s eta 0:05:02\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.5/331.9 MB 813.1 kB/s eta 0:05:37\n",
      "   ------ -------------------------------- 58.7/331.9 MB 603.6 kB/s eta 0:07:33\n",
      "   ------ -------------------------------- 58.7/331.9 MB 603.6 kB/s eta 0:07:33\n",
      "   ------ -------------------------------- 58.7/331.9 MB 603.6 kB/s eta 0:07:33\n",
      "   ------ -------------------------------- 58.7/331.9 MB 603.6 kB/s eta 0:07:33\n",
      "   ------ -------------------------------- 59.0/331.9 MB 525.4 kB/s eta 0:08:40\n",
      "   ------ -------------------------------- 59.0/331.9 MB 525.4 kB/s eta 0:08:40\n",
      "   ------ -------------------------------- 59.2/331.9 MB 482.1 kB/s eta 0:09:26\n",
      "   ------ -------------------------------- 59.2/331.9 MB 482.1 kB/s eta 0:09:26\n",
      "   ------ -------------------------------- 59.5/331.9 MB 446.1 kB/s eta 0:10:11\n",
      "   ------- ------------------------------- 59.8/331.9 MB 445.9 kB/s eta 0:10:11\n",
      "   ------- ------------------------------- 60.0/331.9 MB 448.7 kB/s eta 0:10:06\n",
      "   ------- ------------------------------- 60.3/331.9 MB 454.4 kB/s eta 0:09:58\n",
      "   ------- ------------------------------- 60.6/331.9 MB 455.8 kB/s eta 0:09:56\n",
      "   ------- ------------------------------- 60.8/331.9 MB 457.5 kB/s eta 0:09:53\n",
      "   ------- ------------------------------- 61.1/331.9 MB 463.4 kB/s eta 0:09:45\n",
      "   ------- ------------------------------- 61.3/331.9 MB 463.4 kB/s eta 0:09:44\n",
      "   ------- ------------------------------- 61.6/331.9 MB 463.4 kB/s eta 0:09:44\n",
      "   ------- ------------------------------- 62.1/331.9 MB 474.3 kB/s eta 0:09:29\n",
      "   ------- ------------------------------- 62.1/331.9 MB 474.3 kB/s eta 0:09:29\n",
      "   ------- ------------------------------- 62.4/331.9 MB 479.1 kB/s eta 0:09:23\n",
      "   ------- ------------------------------- 62.7/331.9 MB 485.6 kB/s eta 0:09:15\n",
      "   ------- ------------------------------- 62.9/331.9 MB 486.7 kB/s eta 0:09:13\n",
      "   ------- ------------------------------- 63.4/331.9 MB 500.4 kB/s eta 0:08:57\n",
      "   ------- ------------------------------- 63.7/331.9 MB 504.9 kB/s eta 0:08:52\n",
      "   ------- ------------------------------- 64.0/331.9 MB 510.8 kB/s eta 0:08:45\n",
      "   ------- ------------------------------- 64.2/331.9 MB 525.1 kB/s eta 0:08:30\n",
      "   ------- ------------------------------- 64.5/331.9 MB 531.0 kB/s eta 0:08:24\n",
      "   ------- ------------------------------- 64.7/331.9 MB 534.6 kB/s eta 0:08:20\n",
      "   ------- ------------------------------- 65.0/331.9 MB 540.6 kB/s eta 0:08:14\n",
      "   ------- ------------------------------- 65.3/331.9 MB 546.3 kB/s eta 0:08:09\n",
      "   ------- ------------------------------- 65.5/331.9 MB 552.2 kB/s eta 0:08:03\n",
      "   ------- ------------------------------- 65.8/331.9 MB 555.7 kB/s eta 0:07:59\n",
      "   ------- ------------------------------- 66.1/331.9 MB 559.8 kB/s eta 0:07:55\n",
      "   ------- ------------------------------- 66.1/331.9 MB 559.8 kB/s eta 0:07:55\n",
      "   ------- ------------------------------- 66.1/331.9 MB 559.8 kB/s eta 0:07:55\n",
      "   ------- ------------------------------- 66.3/331.9 MB 544.6 kB/s eta 0:08:08\n",
      "   ------- ------------------------------- 66.3/331.9 MB 544.6 kB/s eta 0:08:08\n",
      "   ------- ------------------------------- 66.3/331.9 MB 544.6 kB/s eta 0:08:08\n",
      "   ------- ------------------------------- 66.3/331.9 MB 544.6 kB/s eta 0:08:08\n",
      "   ------- ------------------------------- 66.3/331.9 MB 544.6 kB/s eta 0:08:08\n",
      "   ------- ------------------------------- 66.3/331.9 MB 544.6 kB/s eta 0:08:08\n",
      "   ------- ------------------------------- 66.3/331.9 MB 544.6 kB/s eta 0:08:08\n",
      "   ------- ------------------------------- 66.6/331.9 MB 498.3 kB/s eta 0:08:53\n",
      "   ------- ------------------------------- 66.6/331.9 MB 498.3 kB/s eta 0:08:53\n",
      "   ------- ------------------------------- 66.6/331.9 MB 498.3 kB/s eta 0:08:53\n",
      "   ------- ------------------------------- 66.6/331.9 MB 498.3 kB/s eta 0:08:53\n",
      "   ------- ------------------------------- 66.6/331.9 MB 498.3 kB/s eta 0:08:53\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 66.8/331.9 MB 568.2 kB/s eta 0:07:47\n",
      "   ------- ------------------------------- 67.1/331.9 MB 524.3 kB/s eta 0:08:26\n",
      "   ------- ------------------------------- 67.1/331.9 MB 524.3 kB/s eta 0:08:26\n",
      "   ------- ------------------------------- 67.1/331.9 MB 524.3 kB/s eta 0:08:26\n",
      "   ------- ------------------------------- 67.1/331.9 MB 524.3 kB/s eta 0:08:26\n",
      "   ------- ------------------------------- 67.1/331.9 MB 524.3 kB/s eta 0:08:26\n",
      "   ------- ------------------------------- 67.1/331.9 MB 524.3 kB/s eta 0:08:26\n",
      "   ------- ------------------------------- 67.4/331.9 MB 511.9 kB/s eta 0:08:37\n",
      "   ------- ------------------------------- 67.4/331.9 MB 511.9 kB/s eta 0:08:37\n",
      "   ------- ------------------------------- 67.4/331.9 MB 511.9 kB/s eta 0:08:37\n",
      "   ------- ------------------------------- 67.4/331.9 MB 511.9 kB/s eta 0:08:37\n",
      "   ------- ------------------------------- 67.6/331.9 MB 506.8 kB/s eta 0:08:42\n",
      "   ------- ------------------------------- 67.6/331.9 MB 506.8 kB/s eta 0:08:42\n",
      "   ------- ------------------------------- 67.6/331.9 MB 506.8 kB/s eta 0:08:42\n",
      "   ------- ------------------------------- 67.9/331.9 MB 555.4 kB/s eta 0:07:56\n",
      "   ------- ------------------------------- 67.9/331.9 MB 555.4 kB/s eta 0:07:56\n",
      "   -------- ------------------------------ 68.2/331.9 MB 554.2 kB/s eta 0:07:56\n",
      "   -------- ------------------------------ 68.2/331.9 MB 554.2 kB/s eta 0:07:56\n",
      "   -------- ------------------------------ 68.2/331.9 MB 554.2 kB/s eta 0:07:56\n",
      "   -------- ------------------------------ 68.4/331.9 MB 554.3 kB/s eta 0:07:56\n",
      "   -------- ------------------------------ 68.4/331.9 MB 554.3 kB/s eta 0:07:56\n",
      "   -------- ------------------------------ 68.7/331.9 MB 555.0 kB/s eta 0:07:55\n",
      "   -------- ------------------------------ 68.7/331.9 MB 555.0 kB/s eta 0:07:55\n",
      "   -------- ------------------------------ 68.9/331.9 MB 556.5 kB/s eta 0:07:53\n",
      "   -------- ------------------------------ 69.2/331.9 MB 558.1 kB/s eta 0:07:51\n",
      "   -------- ------------------------------ 69.2/331.9 MB 558.1 kB/s eta 0:07:51\n",
      "   -------- ------------------------------ 69.5/331.9 MB 560.7 kB/s eta 0:07:49\n",
      "   -------- ------------------------------ 69.7/331.9 MB 572.7 kB/s eta 0:07:38\n",
      "   -------- ------------------------------ 69.7/331.9 MB 572.7 kB/s eta 0:07:38\n",
      "   -------- ------------------------------ 70.0/331.9 MB 576.4 kB/s eta 0:07:35\n",
      "   -------- ------------------------------ 70.3/331.9 MB 580.9 kB/s eta 0:07:31\n",
      "   -------- ------------------------------ 70.5/331.9 MB 585.5 kB/s eta 0:07:27\n",
      "   -------- ------------------------------ 71.0/331.9 MB 599.2 kB/s eta 0:07:16\n",
      "   -------- ------------------------------ 71.3/331.9 MB 604.5 kB/s eta 0:07:12\n",
      "   -------- ------------------------------ 71.6/331.9 MB 612.2 kB/s eta 0:07:06\n",
      "   -------- ------------------------------ 72.1/331.9 MB 623.6 kB/s eta 0:06:57\n",
      "   -------- ------------------------------ 72.6/331.9 MB 637.8 kB/s eta 0:06:47\n",
      "   -------- ------------------------------ 73.1/331.9 MB 650.7 kB/s eta 0:06:38\n",
      "   -------- ------------------------------ 73.7/331.9 MB 664.1 kB/s eta 0:06:29\n",
      "   -------- ------------------------------ 74.2/331.9 MB 679.9 kB/s eta 0:06:20\n",
      "   -------- ------------------------------ 74.7/331.9 MB 693.2 kB/s eta 0:06:11\n",
      "   -------- ------------------------------ 75.5/331.9 MB 714.5 kB/s eta 0:05:59\n",
      "   -------- ------------------------------ 75.8/331.9 MB 720.7 kB/s eta 0:05:56\n",
      "   -------- ------------------------------ 76.5/331.9 MB 742.9 kB/s eta 0:05:44\n",
      "   --------- ----------------------------- 77.3/331.9 MB 763.4 kB/s eta 0:05:34\n",
      "   --------- ----------------------------- 78.4/331.9 MB 791.4 kB/s eta 0:05:21\n",
      "   --------- ----------------------------- 79.2/331.9 MB 813.1 kB/s eta 0:05:11\n",
      "   --------- ----------------------------- 80.2/331.9 MB 841.0 kB/s eta 0:05:00\n",
      "   --------- ----------------------------- 81.3/331.9 MB 872.3 kB/s eta 0:04:48\n",
      "   --------- ----------------------------- 81.8/331.9 MB 880.7 kB/s eta 0:04:44\n",
      "   --------- ----------------------------- 82.1/331.9 MB 888.1 kB/s eta 0:04:42\n",
      "   --------- ----------------------------- 82.3/331.9 MB 892.8 kB/s eta 0:04:40\n",
      "   --------- ----------------------------- 82.8/331.9 MB 897.4 kB/s eta 0:04:38\n",
      "   --------- ----------------------------- 83.1/331.9 MB 901.0 kB/s eta 0:04:37\n",
      "   --------- ----------------------------- 83.4/331.9 MB 914.8 kB/s eta 0:04:32\n",
      "   --------- ----------------------------- 83.6/331.9 MB 918.8 kB/s eta 0:04:31\n",
      "   --------- ----------------------------- 84.1/331.9 MB 921.8 kB/s eta 0:04:29\n",
      "   --------- ----------------------------- 84.4/331.9 MB 935.0 kB/s eta 0:04:25\n",
      "   --------- ----------------------------- 84.7/331.9 MB 938.9 kB/s eta 0:04:24\n",
      "   ---------- ---------------------------- 85.2/331.9 MB 946.2 kB/s eta 0:04:21\n",
      "   ---------- ---------------------------- 85.5/331.9 MB 959.2 kB/s eta 0:04:17\n",
      "   ---------- ---------------------------- 85.5/331.9 MB 959.2 kB/s eta 0:04:17\n",
      "   ---------- ---------------------------- 85.7/331.9 MB 956.9 kB/s eta 0:04:18\n",
      "   ---------- ---------------------------- 86.0/331.9 MB 965.0 kB/s eta 0:04:15\n",
      "   ---------- ---------------------------- 86.0/331.9 MB 965.0 kB/s eta 0:04:15\n",
      "   ---------- ---------------------------- 86.2/331.9 MB 963.7 kB/s eta 0:04:15\n",
      "   ---------- ---------------------------- 86.5/331.9 MB 960.0 kB/s eta 0:04:16\n",
      "   ---------- ---------------------------- 86.5/331.9 MB 960.0 kB/s eta 0:04:16\n",
      "   ---------- ---------------------------- 86.8/331.9 MB 969.1 kB/s eta 0:04:13\n",
      "   ---------- ---------------------------- 87.0/331.9 MB 967.3 kB/s eta 0:04:14\n",
      "   ---------- ---------------------------- 87.0/331.9 MB 967.3 kB/s eta 0:04:14\n",
      "   ---------- ---------------------------- 87.3/331.9 MB 990.1 kB/s eta 0:04:08\n",
      "   ---------- ---------------------------- 87.3/331.9 MB 990.1 kB/s eta 0:04:08\n",
      "   ---------- ---------------------------- 87.6/331.9 MB 990.6 kB/s eta 0:04:07\n",
      "   ---------- ---------------------------- 87.8/331.9 MB 991.1 kB/s eta 0:04:07\n",
      "   ---------- ---------------------------- 88.1/331.9 MB 992.0 kB/s eta 0:04:06\n",
      "   ---------- ----------------------------- 88.3/331.9 MB 1.1 MB/s eta 0:03:51\n",
      "   ---------- ----------------------------- 88.6/331.9 MB 1.1 MB/s eta 0:03:51\n",
      "   ---------- ----------------------------- 88.9/331.9 MB 1.1 MB/s eta 0:03:50\n",
      "   ---------- ----------------------------- 89.1/331.9 MB 1.1 MB/s eta 0:03:50\n",
      "   ---------- ----------------------------- 89.4/331.9 MB 1.1 MB/s eta 0:03:50\n",
      "   ---------- ----------------------------- 89.7/331.9 MB 1.1 MB/s eta 0:03:49\n",
      "   ---------- ----------------------------- 89.9/331.9 MB 1.1 MB/s eta 0:03:49\n",
      "   ---------- ----------------------------- 90.2/331.9 MB 1.1 MB/s eta 0:03:48\n",
      "   ---------- ----------------------------- 90.4/331.9 MB 1.1 MB/s eta 0:03:47\n",
      "   ---------- ----------------------------- 90.4/331.9 MB 1.1 MB/s eta 0:03:47\n",
      "   ---------- ----------------------------- 90.7/331.9 MB 1.1 MB/s eta 0:03:44\n",
      "   ---------- ----------------------------- 91.2/331.9 MB 1.1 MB/s eta 0:03:43\n",
      "   ----------- ---------------------------- 91.5/331.9 MB 1.1 MB/s eta 0:03:42\n",
      "   ----------- ---------------------------- 91.8/331.9 MB 1.1 MB/s eta 0:03:40\n",
      "   ----------- ---------------------------- 92.0/331.9 MB 1.1 MB/s eta 0:03:39\n",
      "   ----------- ---------------------------- 92.3/331.9 MB 1.1 MB/s eta 0:03:38\n",
      "   ----------- ---------------------------- 92.5/331.9 MB 1.1 MB/s eta 0:03:37\n",
      "   ----------- ---------------------------- 93.1/331.9 MB 1.1 MB/s eta 0:03:35\n",
      "   ----------- ---------------------------- 93.3/331.9 MB 1.1 MB/s eta 0:03:34\n",
      "   ----------- ---------------------------- 93.6/331.9 MB 1.1 MB/s eta 0:03:33\n",
      "   ----------- ---------------------------- 94.1/331.9 MB 1.1 MB/s eta 0:03:32\n",
      "   ----------- ---------------------------- 94.4/331.9 MB 1.1 MB/s eta 0:03:32\n",
      "   ----------- ---------------------------- 94.6/331.9 MB 1.1 MB/s eta 0:03:32\n",
      "   ----------- ---------------------------- 95.2/331.9 MB 1.1 MB/s eta 0:03:30\n",
      "   ----------- ---------------------------- 95.4/331.9 MB 1.1 MB/s eta 0:03:30\n",
      "   ----------- ---------------------------- 95.7/331.9 MB 1.1 MB/s eta 0:03:30\n",
      "   ----------- ---------------------------- 95.9/331.9 MB 1.1 MB/s eta 0:03:29\n",
      "   ----------- ---------------------------- 96.2/331.9 MB 1.1 MB/s eta 0:03:29\n",
      "   ----------- ---------------------------- 96.7/331.9 MB 1.1 MB/s eta 0:03:28\n",
      "   ----------- ---------------------------- 96.7/331.9 MB 1.1 MB/s eta 0:03:28\n",
      "   ----------- ---------------------------- 97.0/331.9 MB 1.1 MB/s eta 0:03:27\n",
      "   ----------- ---------------------------- 97.3/331.9 MB 1.1 MB/s eta 0:03:28\n",
      "   ----------- ---------------------------- 97.5/331.9 MB 1.1 MB/s eta 0:03:28\n",
      "   ----------- ---------------------------- 97.8/331.9 MB 1.1 MB/s eta 0:03:28\n",
      "   ----------- ---------------------------- 98.0/331.9 MB 1.1 MB/s eta 0:03:27\n",
      "   ----------- ---------------------------- 98.3/331.9 MB 1.1 MB/s eta 0:03:27\n",
      "   ----------- ---------------------------- 98.6/331.9 MB 1.1 MB/s eta 0:03:27\n",
      "   ----------- ---------------------------- 99.1/331.9 MB 1.1 MB/s eta 0:03:26\n",
      "   ----------- ---------------------------- 99.4/331.9 MB 1.1 MB/s eta 0:03:27\n",
      "   ------------ --------------------------- 99.6/331.9 MB 1.1 MB/s eta 0:03:27\n",
      "   ------------ --------------------------- 99.6/331.9 MB 1.1 MB/s eta 0:03:27\n",
      "   ------------ --------------------------- 99.9/331.9 MB 1.1 MB/s eta 0:03:26\n",
      "   ------------ --------------------------- 100.4/331.9 MB 1.1 MB/s eta 0:03:23\n",
      "   ------------ --------------------------- 100.7/331.9 MB 1.1 MB/s eta 0:03:22\n",
      "   ------------ --------------------------- 100.9/331.9 MB 1.2 MB/s eta 0:03:14\n",
      "   ------------ --------------------------- 101.2/331.9 MB 1.2 MB/s eta 0:03:14\n",
      "   ------------ --------------------------- 101.4/331.9 MB 1.2 MB/s eta 0:03:13\n",
      "   ------------ --------------------------- 101.7/331.9 MB 1.2 MB/s eta 0:03:12\n",
      "   ------------ --------------------------- 102.2/331.9 MB 1.2 MB/s eta 0:03:11\n",
      "   ------------ --------------------------- 102.5/331.9 MB 1.2 MB/s eta 0:03:11\n",
      "   ------------ --------------------------- 102.8/331.9 MB 1.2 MB/s eta 0:03:05\n",
      "   ------------ --------------------------- 103.0/331.9 MB 1.2 MB/s eta 0:03:05\n",
      "   ------------ --------------------------- 103.3/331.9 MB 1.2 MB/s eta 0:03:04\n",
      "   ------------ --------------------------- 103.5/331.9 MB 1.2 MB/s eta 0:03:04\n",
      "   ------------ --------------------------- 104.1/331.9 MB 1.2 MB/s eta 0:03:03\n",
      "   ------------ --------------------------- 104.1/331.9 MB 1.2 MB/s eta 0:03:03\n",
      "   ------------ --------------------------- 104.6/331.9 MB 1.4 MB/s eta 0:02:47\n",
      "   ------------ --------------------------- 104.9/331.9 MB 1.4 MB/s eta 0:02:47\n",
      "   ------------ --------------------------- 105.1/331.9 MB 1.4 MB/s eta 0:02:47\n",
      "   ------------ --------------------------- 105.6/331.9 MB 1.4 MB/s eta 0:02:46\n",
      "   ------------ --------------------------- 105.9/331.9 MB 1.4 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 106.4/331.9 MB 1.4 MB/s eta 0:02:45\n",
      "   ------------ --------------------------- 106.7/331.9 MB 1.4 MB/s eta 0:02:44\n",
      "   ------------ --------------------------- 107.2/331.9 MB 1.4 MB/s eta 0:02:43\n",
      "   ------------ --------------------------- 107.5/331.9 MB 1.4 MB/s eta 0:02:43\n",
      "   ------------ --------------------------- 107.7/331.9 MB 1.4 MB/s eta 0:02:43\n",
      "   ------------- -------------------------- 108.0/331.9 MB 1.4 MB/s eta 0:02:43\n",
      "   ------------- -------------------------- 108.3/331.9 MB 1.4 MB/s eta 0:02:43\n",
      "   ------------- -------------------------- 108.5/331.9 MB 1.4 MB/s eta 0:02:42\n",
      "   ------------- -------------------------- 109.1/331.9 MB 1.4 MB/s eta 0:02:36\n",
      "   ------------- -------------------------- 109.3/331.9 MB 1.4 MB/s eta 0:02:36\n",
      "   ------------- -------------------------- 109.6/331.9 MB 1.4 MB/s eta 0:02:35\n",
      "   ------------- -------------------------- 109.8/331.9 MB 1.4 MB/s eta 0:02:35\n",
      "   ------------- -------------------------- 110.1/331.9 MB 1.4 MB/s eta 0:02:35\n",
      "   ------------- -------------------------- 110.4/331.9 MB 1.5 MB/s eta 0:02:32\n",
      "   ------------- -------------------------- 110.9/331.9 MB 1.5 MB/s eta 0:02:31\n",
      "   ------------- -------------------------- 111.4/331.9 MB 1.5 MB/s eta 0:02:30\n",
      "   ------------- -------------------------- 111.4/331.9 MB 1.5 MB/s eta 0:02:30\n",
      "   ------------- -------------------------- 111.9/331.9 MB 1.5 MB/s eta 0:02:28\n",
      "   ------------- -------------------------- 112.2/331.9 MB 1.5 MB/s eta 0:02:28\n",
      "   ------------- -------------------------- 112.2/331.9 MB 1.5 MB/s eta 0:02:28\n",
      "   ------------- -------------------------- 112.7/331.9 MB 1.5 MB/s eta 0:02:26\n",
      "   ------------- -------------------------- 113.2/331.9 MB 1.5 MB/s eta 0:02:25\n",
      "   ------------- -------------------------- 114.0/331.9 MB 1.5 MB/s eta 0:02:22\n",
      "   ------------- -------------------------- 114.8/331.9 MB 1.6 MB/s eta 0:02:20\n",
      "   ------------- -------------------------- 115.1/331.9 MB 1.6 MB/s eta 0:02:20\n",
      "   ------------- -------------------------- 115.6/331.9 MB 1.6 MB/s eta 0:02:18\n",
      "   ------------- -------------------------- 115.6/331.9 MB 1.6 MB/s eta 0:02:18\n",
      "   -------------- ------------------------- 116.7/331.9 MB 1.6 MB/s eta 0:02:15\n",
      "   -------------- ------------------------- 117.2/331.9 MB 1.6 MB/s eta 0:02:13\n",
      "   -------------- ------------------------- 117.7/331.9 MB 1.6 MB/s eta 0:02:12\n",
      "   -------------- ------------------------- 117.7/331.9 MB 1.6 MB/s eta 0:02:12\n",
      "   -------------- ------------------------- 118.0/331.9 MB 1.6 MB/s eta 0:02:13\n",
      "   -------------- ------------------------- 118.8/331.9 MB 1.6 MB/s eta 0:02:10\n",
      "   -------------- ------------------------- 119.0/331.9 MB 1.6 MB/s eta 0:02:10\n",
      "   -------------- ------------------------- 119.0/331.9 MB 1.6 MB/s eta 0:02:10\n",
      "   -------------- ------------------------- 119.5/331.9 MB 1.6 MB/s eta 0:02:10\n",
      "   -------------- ------------------------- 119.8/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 120.1/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 120.3/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 120.6/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 121.1/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 121.6/331.9 MB 1.6 MB/s eta 0:02:08\n",
      "   -------------- ------------------------- 121.9/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 122.4/331.9 MB 1.6 MB/s eta 0:02:08\n",
      "   -------------- ------------------------- 122.9/331.9 MB 1.6 MB/s eta 0:02:08\n",
      "   -------------- ------------------------- 123.2/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 123.7/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   -------------- ------------------------- 124.3/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   --------------- ------------------------ 124.5/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   --------------- ------------------------ 125.0/331.9 MB 1.6 MB/s eta 0:02:10\n",
      "   --------------- ------------------------ 125.6/331.9 MB 1.6 MB/s eta 0:02:10\n",
      "   --------------- ------------------------ 126.1/331.9 MB 1.6 MB/s eta 0:02:11\n",
      "   --------------- ------------------------ 126.4/331.9 MB 1.6 MB/s eta 0:02:12\n",
      "   --------------- ------------------------ 126.9/331.9 MB 1.5 MB/s eta 0:02:14\n",
      "   --------------- ------------------------ 127.1/331.9 MB 1.5 MB/s eta 0:02:15\n",
      "   --------------- ------------------------ 127.7/331.9 MB 1.5 MB/s eta 0:02:15\n",
      "   --------------- ------------------------ 128.2/331.9 MB 1.5 MB/s eta 0:02:14\n",
      "   --------------- ------------------------ 128.5/331.9 MB 1.5 MB/s eta 0:02:13\n",
      "   --------------- ------------------------ 129.0/331.9 MB 1.5 MB/s eta 0:02:13\n",
      "   --------------- ------------------------ 129.2/331.9 MB 1.5 MB/s eta 0:02:12\n",
      "   --------------- ------------------------ 129.8/331.9 MB 1.5 MB/s eta 0:02:12\n",
      "   --------------- ------------------------ 130.3/331.9 MB 1.5 MB/s eta 0:02:11\n",
      "   --------------- ------------------------ 130.8/331.9 MB 1.6 MB/s eta 0:02:10\n",
      "   --------------- ------------------------ 131.3/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   --------------- ------------------------ 131.6/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   --------------- ------------------------ 132.1/331.9 MB 1.6 MB/s eta 0:02:09\n",
      "   --------------- ------------------------ 132.4/331.9 MB 1.6 MB/s eta 0:02:07\n",
      "   ---------------- ----------------------- 132.9/331.9 MB 1.6 MB/s eta 0:02:07\n",
      "   ---------------- ----------------------- 133.2/331.9 MB 1.6 MB/s eta 0:02:06\n",
      "   ---------------- ----------------------- 133.7/331.9 MB 1.6 MB/s eta 0:02:05\n",
      "   ---------------- ----------------------- 134.2/331.9 MB 1.6 MB/s eta 0:02:04\n",
      "   ---------------- ----------------------- 134.2/331.9 MB 1.6 MB/s eta 0:02:04\n",
      "   ---------------- ----------------------- 134.7/331.9 MB 1.6 MB/s eta 0:02:03\n",
      "   ---------------- ----------------------- 135.0/331.9 MB 1.6 MB/s eta 0:02:03\n",
      "   ---------------- ----------------------- 135.5/331.9 MB 1.6 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 135.5/331.9 MB 1.6 MB/s eta 0:02:02\n",
      "   ---------------- ----------------------- 135.8/331.9 MB 1.6 MB/s eta 0:02:01\n",
      "   ---------------- ----------------------- 136.6/331.9 MB 1.6 MB/s eta 0:01:59\n",
      "   ---------------- ----------------------- 137.1/331.9 MB 1.7 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 137.4/331.9 MB 1.7 MB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 137.9/331.9 MB 1.7 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 138.1/331.9 MB 1.7 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 138.1/331.9 MB 1.7 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 138.7/331.9 MB 1.7 MB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 138.9/331.9 MB 1.7 MB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 139.5/331.9 MB 1.7 MB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 140.2/331.9 MB 1.7 MB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 140.8/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 141.3/331.9 MB 1.7 MB/s eta 0:01:52\n",
      "   ----------------- ---------------------- 141.6/331.9 MB 1.7 MB/s eta 0:01:52\n",
      "   ----------------- ---------------------- 141.8/331.9 MB 1.7 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 141.8/331.9 MB 1.7 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 142.1/331.9 MB 1.7 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 142.1/331.9 MB 1.7 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 142.1/331.9 MB 1.7 MB/s eta 0:01:51\n",
      "   ----------------- ---------------------- 142.3/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 142.3/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 142.3/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 142.3/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 142.3/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 142.3/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 142.3/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 142.3/331.9 MB 1.7 MB/s eta 0:01:53\n",
      "   ----------------- ---------------------- 142.6/331.9 MB 1.6 MB/s eta 0:01:58\n",
      "   ----------------- ---------------------- 142.9/331.9 MB 1.6 MB/s eta 0:01:58\n",
      "   ----------------- ---------------------- 142.9/331.9 MB 1.6 MB/s eta 0:01:58\n",
      "   ----------------- ---------------------- 143.1/331.9 MB 1.6 MB/s eta 0:01:59\n",
      "   ----------------- ---------------------- 143.1/331.9 MB 1.6 MB/s eta 0:01:59\n",
      "   ----------------- ---------------------- 143.4/331.9 MB 1.6 MB/s eta 0:02:00\n",
      "   ----------------- ---------------------- 143.4/331.9 MB 1.6 MB/s eta 0:02:00\n",
      "   ----------------- ---------------------- 143.4/331.9 MB 1.6 MB/s eta 0:02:00\n",
      "   ----------------- ---------------------- 143.7/331.9 MB 1.6 MB/s eta 0:02:01\n",
      "   ----------------- ---------------------- 143.7/331.9 MB 1.6 MB/s eta 0:02:01\n",
      "   ----------------- ---------------------- 143.9/331.9 MB 1.5 MB/s eta 0:02:02\n",
      "   ----------------- ---------------------- 144.2/331.9 MB 1.5 MB/s eta 0:02:02\n",
      "   ----------------- ---------------------- 144.4/331.9 MB 1.6 MB/s eta 0:02:01\n",
      "   ----------------- ---------------------- 145.0/331.9 MB 1.6 MB/s eta 0:02:01\n",
      "   ----------------- ---------------------- 145.2/331.9 MB 1.6 MB/s eta 0:02:00\n",
      "   ----------------- ---------------------- 145.8/331.9 MB 1.6 MB/s eta 0:02:00\n",
      "   ----------------- ---------------------- 146.0/331.9 MB 1.6 MB/s eta 0:01:59\n",
      "   ----------------- ---------------------- 146.5/331.9 MB 1.6 MB/s eta 0:01:58\n",
      "   ----------------- ---------------------- 147.1/331.9 MB 1.6 MB/s eta 0:01:57\n",
      "   ----------------- ---------------------- 147.6/331.9 MB 1.6 MB/s eta 0:01:56\n",
      "   ----------------- ---------------------- 148.4/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ----------------- ---------------------- 148.6/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ----------------- ---------------------- 149.2/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 149.4/331.9 MB 1.6 MB/s eta 0:01:53\n",
      "   ------------------ --------------------- 149.7/331.9 MB 1.6 MB/s eta 0:01:53\n",
      "   ------------------ --------------------- 149.9/331.9 MB 1.6 MB/s eta 0:01:53\n",
      "   ------------------ --------------------- 150.2/331.9 MB 1.6 MB/s eta 0:01:53\n",
      "   ------------------ --------------------- 150.5/331.9 MB 1.6 MB/s eta 0:01:53\n",
      "   ------------------ --------------------- 150.5/331.9 MB 1.6 MB/s eta 0:01:53\n",
      "   ------------------ --------------------- 150.7/331.9 MB 1.6 MB/s eta 0:01:53\n",
      "   ------------------ --------------------- 151.0/331.9 MB 1.6 MB/s eta 0:01:53\n",
      "   ------------------ --------------------- 151.3/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.3/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.5/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.8/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.8/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.8/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.8/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.8/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.8/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 151.8/331.9 MB 1.6 MB/s eta 0:01:54\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.0/331.9 MB 1.5 MB/s eta 0:02:00\n",
      "   ------------------ --------------------- 152.3/331.9 MB 1.4 MB/s eta 0:02:07\n",
      "   ------------------ --------------------- 152.3/331.9 MB 1.4 MB/s eta 0:02:07\n",
      "   ------------------ --------------------- 152.3/331.9 MB 1.4 MB/s eta 0:02:07\n",
      "   ------------------ --------------------- 152.3/331.9 MB 1.4 MB/s eta 0:02:07\n",
      "   ------------------ --------------------- 152.3/331.9 MB 1.4 MB/s eta 0:02:07\n",
      "   ------------------ --------------------- 152.3/331.9 MB 1.4 MB/s eta 0:02:07\n",
      "   ------------------ --------------------- 152.3/331.9 MB 1.4 MB/s eta 0:02:07\n",
      "   ------------------ --------------------- 152.6/331.9 MB 1.4 MB/s eta 0:02:12\n",
      "   ------------------ --------------------- 152.6/331.9 MB 1.4 MB/s eta 0:02:12\n",
      "   ------------------ --------------------- 152.6/331.9 MB 1.4 MB/s eta 0:02:12\n",
      "   ------------------ --------------------- 152.8/331.9 MB 1.3 MB/s eta 0:02:14\n",
      "   ------------------ --------------------- 152.8/331.9 MB 1.3 MB/s eta 0:02:14\n",
      "   ------------------ --------------------- 152.8/331.9 MB 1.3 MB/s eta 0:02:14\n",
      "   ------------------ --------------------- 152.8/331.9 MB 1.3 MB/s eta 0:02:14\n",
      "   ------------------ --------------------- 153.1/331.9 MB 1.3 MB/s eta 0:02:22\n",
      "   ------------------ --------------------- 153.1/331.9 MB 1.3 MB/s eta 0:02:22\n",
      "   ------------------ --------------------- 153.4/331.9 MB 1.3 MB/s eta 0:02:23\n",
      "   ------------------ --------------------- 153.4/331.9 MB 1.3 MB/s eta 0:02:23\n",
      "   ------------------ --------------------- 153.6/331.9 MB 1.2 MB/s eta 0:02:25\n",
      "   ------------------ --------------------- 153.9/331.9 MB 1.2 MB/s eta 0:02:28\n",
      "   ------------------ --------------------- 153.9/331.9 MB 1.2 MB/s eta 0:02:28\n",
      "   ------------------ --------------------- 154.1/331.9 MB 1.2 MB/s eta 0:02:28\n",
      "   ------------------ --------------------- 154.4/331.9 MB 1.2 MB/s eta 0:02:30\n",
      "   ------------------ --------------------- 154.4/331.9 MB 1.2 MB/s eta 0:02:30\n",
      "   ------------------ --------------------- 154.9/331.9 MB 1.2 MB/s eta 0:02:29\n",
      "   ------------------ --------------------- 155.2/331.9 MB 1.2 MB/s eta 0:02:29\n",
      "   ------------------ --------------------- 155.5/331.9 MB 1.2 MB/s eta 0:02:29\n",
      "   ------------------ --------------------- 156.0/331.9 MB 1.2 MB/s eta 0:02:28\n",
      "   ------------------ --------------------- 156.2/331.9 MB 1.2 MB/s eta 0:02:27\n",
      "   ------------------ --------------------- 156.8/331.9 MB 1.2 MB/s eta 0:02:26\n",
      "   ------------------ --------------------- 157.5/331.9 MB 1.2 MB/s eta 0:02:24\n",
      "   ------------------ --------------------- 157.5/331.9 MB 1.2 MB/s eta 0:02:24\n",
      "   ------------------- -------------------- 157.8/331.9 MB 1.2 MB/s eta 0:02:26\n",
      "   ------------------- -------------------- 158.1/331.9 MB 1.2 MB/s eta 0:02:25\n",
      "   ------------------- -------------------- 158.1/331.9 MB 1.2 MB/s eta 0:02:25\n",
      "   ------------------- -------------------- 158.6/331.9 MB 1.2 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 159.1/331.9 MB 1.2 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 159.4/331.9 MB 1.2 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 160.2/331.9 MB 1.2 MB/s eta 0:02:25\n",
      "   ------------------- -------------------- 160.2/331.9 MB 1.2 MB/s eta 0:02:25\n",
      "   ------------------- -------------------- 160.4/331.9 MB 1.2 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 160.4/331.9 MB 1.2 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 160.4/331.9 MB 1.2 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 160.4/331.9 MB 1.2 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 160.7/331.9 MB 1.1 MB/s eta 0:02:34\n",
      "   ------------------- -------------------- 161.5/331.9 MB 1.1 MB/s eta 0:02:31\n",
      "   ------------------- -------------------- 162.3/331.9 MB 1.1 MB/s eta 0:02:29\n",
      "   ------------------- -------------------- 162.3/331.9 MB 1.1 MB/s eta 0:02:29\n",
      "   ------------------- -------------------- 163.3/331.9 MB 1.1 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 163.6/331.9 MB 1.2 MB/s eta 0:02:26\n",
      "   ------------------- -------------------- 163.8/331.9 MB 1.1 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 163.8/331.9 MB 1.1 MB/s eta 0:02:27\n",
      "   ------------------- -------------------- 164.4/331.9 MB 1.1 MB/s eta 0:02:30\n",
      "   ------------------- -------------------- 165.2/331.9 MB 1.1 MB/s eta 0:02:27\n",
      "   -------------------- ------------------- 166.5/331.9 MB 1.2 MB/s eta 0:02:23\n",
      "   -------------------- ------------------- 166.5/331.9 MB 1.2 MB/s eta 0:02:23\n",
      "   -------------------- ------------------- 168.0/331.9 MB 1.2 MB/s eta 0:02:18\n",
      "   -------------------- ------------------- 168.0/331.9 MB 1.2 MB/s eta 0:02:18\n",
      "   -------------------- ------------------- 168.0/331.9 MB 1.2 MB/s eta 0:02:18\n",
      "   -------------------- ------------------- 168.0/331.9 MB 1.2 MB/s eta 0:02:18\n",
      "   -------------------- ------------------- 168.3/331.9 MB 1.1 MB/s eta 0:02:23\n",
      "   -------------------- ------------------- 168.8/331.9 MB 1.2 MB/s eta 0:02:22\n",
      "   -------------------- ------------------- 170.7/331.9 MB 1.2 MB/s eta 0:02:15\n",
      "   -------------------- ------------------- 170.9/331.9 MB 1.2 MB/s eta 0:02:15\n",
      "   -------------------- ------------------- 170.9/331.9 MB 1.2 MB/s eta 0:02:15\n",
      "   -------------------- ------------------- 171.4/331.9 MB 1.2 MB/s eta 0:02:15\n",
      "   -------------------- ------------------- 173.5/331.9 MB 1.3 MB/s eta 0:02:07\n",
      "   -------------------- ------------------- 173.5/331.9 MB 1.3 MB/s eta 0:02:07\n",
      "   -------------------- ------------------- 173.8/331.9 MB 1.2 MB/s eta 0:02:09\n",
      "   --------------------- ------------------ 175.9/331.9 MB 1.3 MB/s eta 0:02:02\n",
      "   --------------------- ------------------ 177.5/331.9 MB 1.3 MB/s eta 0:01:57\n",
      "   --------------------- ------------------ 179.3/331.9 MB 1.4 MB/s eta 0:01:52\n",
      "   --------------------- ------------------ 179.3/331.9 MB 1.4 MB/s eta 0:01:52\n",
      "   --------------------- ------------------ 181.9/331.9 MB 1.4 MB/s eta 0:01:44\n",
      "   --------------------- ------------------ 182.2/331.9 MB 1.4 MB/s eta 0:01:44\n",
      "   ---------------------- ----------------- 183.5/331.9 MB 1.5 MB/s eta 0:01:41\n",
      "   ---------------------- ----------------- 185.6/331.9 MB 1.5 MB/s eta 0:01:37\n",
      "   ---------------------- ----------------- 185.6/331.9 MB 1.5 MB/s eta 0:01:37\n",
      "   ---------------------- ----------------- 185.6/331.9 MB 1.5 MB/s eta 0:01:37\n",
      "   ---------------------- ----------------- 186.6/331.9 MB 1.5 MB/s eta 0:01:37\n",
      "   ---------------------- ----------------- 187.2/331.9 MB 1.5 MB/s eta 0:01:36\n",
      "   ---------------------- ----------------- 188.5/331.9 MB 1.6 MB/s eta 0:01:33\n",
      "   ---------------------- ----------------- 189.3/331.9 MB 1.6 MB/s eta 0:01:31\n",
      "   ---------------------- ----------------- 190.6/331.9 MB 1.6 MB/s eta 0:01:28\n",
      "   ----------------------- ---------------- 191.6/331.9 MB 1.7 MB/s eta 0:01:25\n",
      "   ----------------------- ---------------- 191.9/331.9 MB 1.7 MB/s eta 0:01:21\n",
      "   ----------------------- ---------------- 192.9/331.9 MB 1.8 MB/s eta 0:01:20\n",
      "   ----------------------- ---------------- 194.0/331.9 MB 1.8 MB/s eta 0:01:18\n",
      "   ----------------------- ---------------- 194.5/331.9 MB 1.8 MB/s eta 0:01:17\n",
      "   ----------------------- ---------------- 196.3/331.9 MB 1.8 MB/s eta 0:01:14\n",
      "   ----------------------- ---------------- 197.1/331.9 MB 1.9 MB/s eta 0:01:13\n",
      "   ----------------------- ---------------- 197.7/331.9 MB 1.9 MB/s eta 0:01:13\n",
      "   ----------------------- ---------------- 197.9/331.9 MB 1.8 MB/s eta 0:01:13\n",
      "   ----------------------- ---------------- 198.2/331.9 MB 1.9 MB/s eta 0:01:13\n",
      "   ----------------------- ---------------- 198.2/331.9 MB 1.9 MB/s eta 0:01:13\n",
      "   ------------------------ --------------- 199.2/331.9 MB 1.9 MB/s eta 0:01:11\n",
      "   ------------------------ --------------- 199.5/331.9 MB 1.9 MB/s eta 0:01:11\n",
      "   ------------------------ --------------- 199.5/331.9 MB 1.9 MB/s eta 0:01:11\n",
      "   ------------------------ --------------- 199.5/331.9 MB 1.9 MB/s eta 0:01:11\n",
      "   ------------------------ --------------- 200.5/331.9 MB 1.9 MB/s eta 0:01:09\n",
      "   ------------------------ --------------- 201.9/331.9 MB 1.9 MB/s eta 0:01:07\n",
      "   ------------------------ --------------- 202.6/331.9 MB 2.0 MB/s eta 0:01:06\n",
      "   ------------------------ --------------- 202.9/331.9 MB 2.0 MB/s eta 0:01:05\n",
      "   ------------------------ --------------- 202.9/331.9 MB 2.0 MB/s eta 0:01:05\n",
      "   ------------------------ --------------- 203.7/331.9 MB 2.0 MB/s eta 0:01:05\n",
      "   ------------------------ --------------- 203.9/331.9 MB 2.0 MB/s eta 0:01:05\n",
      "   ------------------------ --------------- 204.7/331.9 MB 2.0 MB/s eta 0:01:04\n",
      "   ------------------------ --------------- 205.8/331.9 MB 2.0 MB/s eta 0:01:03\n",
      "   ------------------------ --------------- 206.0/331.9 MB 2.0 MB/s eta 0:01:03\n",
      "   ------------------------ --------------- 207.1/331.9 MB 2.0 MB/s eta 0:01:02\n",
      "   ------------------------- -------------- 208.7/331.9 MB 2.1 MB/s eta 0:01:00\n",
      "   ------------------------- -------------- 209.7/331.9 MB 2.1 MB/s eta 0:00:59\n",
      "   ------------------------- -------------- 211.3/331.9 MB 2.1 MB/s eta 0:00:58\n",
      "   ------------------------- -------------- 211.6/331.9 MB 2.1 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 212.1/331.9 MB 2.1 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 212.6/331.9 MB 2.1 MB/s eta 0:00:57\n",
      "   ------------------------- -------------- 213.9/331.9 MB 2.2 MB/s eta 0:00:55\n",
      "   ------------------------- -------------- 215.2/331.9 MB 2.2 MB/s eta 0:00:54\n",
      "   -------------------------- ------------- 216.0/331.9 MB 2.2 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 216.5/331.9 MB 2.2 MB/s eta 0:00:53\n",
      "   -------------------------- ------------- 217.1/331.9 MB 2.2 MB/s eta 0:00:52\n",
      "   -------------------------- ------------- 217.8/331.9 MB 2.2 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 218.1/331.9 MB 2.2 MB/s eta 0:00:51\n",
      "   -------------------------- ------------- 218.9/331.9 MB 2.3 MB/s eta 0:00:50\n",
      "   -------------------------- ------------- 219.2/331.9 MB 2.3 MB/s eta 0:00:50\n",
      "   -------------------------- ------------- 219.4/331.9 MB 2.3 MB/s eta 0:00:50\n",
      "   -------------------------- ------------- 220.2/331.9 MB 2.3 MB/s eta 0:00:49\n",
      "   -------------------------- ------------- 220.7/331.9 MB 2.4 MB/s eta 0:00:47\n",
      "   -------------------------- ------------- 221.2/331.9 MB 2.4 MB/s eta 0:00:47\n",
      "   -------------------------- ------------- 221.8/331.9 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 222.3/331.9 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 223.1/331.9 MB 2.4 MB/s eta 0:00:46\n",
      "   -------------------------- ------------- 223.3/331.9 MB 2.4 MB/s eta 0:00:45\n",
      "   -------------------------- ------------- 223.9/331.9 MB 2.4 MB/s eta 0:00:45\n",
      "   --------------------------- ------------ 224.4/331.9 MB 2.6 MB/s eta 0:00:43\n",
      "   --------------------------- ------------ 224.9/331.9 MB 2.6 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 225.2/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 225.7/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 226.2/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 226.8/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 227.0/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 227.0/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 227.3/331.9 MB 2.5 MB/s eta 0:00:42\n",
      "   --------------------------- ------------ 227.5/331.9 MB 2.6 MB/s eta 0:00:40\n",
      "   --------------------------- ------------ 227.8/331.9 MB 2.6 MB/s eta 0:00:40\n",
      "   --------------------------- ------------ 228.1/331.9 MB 2.6 MB/s eta 0:00:41\n",
      "   --------------------------- ------------ 228.3/331.9 MB 2.6 MB/s eta 0:00:41\n",
      "   --------------------------- ------------ 228.6/331.9 MB 2.6 MB/s eta 0:00:41\n",
      "   --------------------------- ------------ 228.9/331.9 MB 2.6 MB/s eta 0:00:41\n",
      "   --------------------------- ------------ 229.1/331.9 MB 2.6 MB/s eta 0:00:41\n",
      "   --------------------------- ------------ 229.4/331.9 MB 2.6 MB/s eta 0:00:40\n",
      "   --------------------------- ------------ 229.4/331.9 MB 2.6 MB/s eta 0:00:40\n",
      "   --------------------------- ------------ 229.6/331.9 MB 2.6 MB/s eta 0:00:40\n",
      "   --------------------------- ------------ 229.9/331.9 MB 2.6 MB/s eta 0:00:40\n",
      "   --------------------------- ------------ 230.2/331.9 MB 2.6 MB/s eta 0:00:39\n",
      "   --------------------------- ------------ 230.7/331.9 MB 2.6 MB/s eta 0:00:39\n",
      "   --------------------------- ------------ 230.9/331.9 MB 2.6 MB/s eta 0:00:39\n",
      "   --------------------------- ------------ 231.2/331.9 MB 2.6 MB/s eta 0:00:39\n",
      "   --------------------------- ------------ 231.5/331.9 MB 2.6 MB/s eta 0:00:39\n",
      "   --------------------------- ------------ 231.7/331.9 MB 2.6 MB/s eta 0:00:39\n",
      "   --------------------------- ------------ 232.0/331.9 MB 2.6 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 232.5/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 232.8/331.9 MB 2.7 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 233.0/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 233.3/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 233.3/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 233.3/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 233.6/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 233.6/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 233.8/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 233.8/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 234.1/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 234.1/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 234.4/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 234.4/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 234.6/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 234.9/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 234.9/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 235.1/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 235.1/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 235.4/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 235.7/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 235.7/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 235.9/331.9 MB 2.5 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 236.2/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 236.5/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 236.5/331.9 MB 2.6 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 236.7/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 237.0/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 237.2/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 237.5/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 237.5/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 237.5/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 237.8/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 237.8/331.9 MB 2.5 MB/s eta 0:00:38\n",
      "   ---------------------------- ----------- 238.0/331.9 MB 2.5 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 238.3/331.9 MB 2.4 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 238.3/331.9 MB 2.4 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 238.6/331.9 MB 2.4 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 238.8/331.9 MB 2.4 MB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 238.8/331.9 MB 2.4 MB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 239.1/331.9 MB 2.4 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 239.3/331.9 MB 2.4 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 239.6/331.9 MB 2.4 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 239.6/331.9 MB 2.4 MB/s eta 0:00:39\n",
      "   ---------------------------- ----------- 239.9/331.9 MB 2.3 MB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 239.9/331.9 MB 2.3 MB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 239.9/331.9 MB 2.3 MB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 240.1/331.9 MB 2.3 MB/s eta 0:00:40\n",
      "   ---------------------------- ----------- 240.4/331.9 MB 2.2 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 240.6/331.9 MB 2.2 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 240.9/331.9 MB 2.2 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 240.9/331.9 MB 2.2 MB/s eta 0:00:41\n",
      "   ----------------------------- ---------- 241.2/331.9 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 241.7/331.9 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 242.2/331.9 MB 2.1 MB/s eta 0:00:43\n",
      "   ----------------------------- ---------- 242.7/331.9 MB 2.1 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 243.3/331.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 243.3/331.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 243.8/331.9 MB 2.0 MB/s eta 0:00:45\n",
      "   ----------------------------- ---------- 244.3/331.9 MB 2.0 MB/s eta 0:00:45\n",
      "   ----------------------------- ---------- 245.1/331.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 245.6/331.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 245.6/331.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 245.6/331.9 MB 2.0 MB/s eta 0:00:44\n",
      "   ----------------------------- ---------- 246.2/331.9 MB 1.9 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 246.7/331.9 MB 1.9 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 247.2/331.9 MB 1.9 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 247.7/331.9 MB 1.9 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 248.0/331.9 MB 1.9 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 248.8/331.9 MB 1.8 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 248.8/331.9 MB 1.8 MB/s eta 0:00:46\n",
      "   ----------------------------- ---------- 248.8/331.9 MB 1.8 MB/s eta 0:00:46\n",
      "   ------------------------------ --------- 249.0/331.9 MB 1.7 MB/s eta 0:00:48\n",
      "   ------------------------------ --------- 250.3/331.9 MB 1.8 MB/s eta 0:00:47\n",
      "   ------------------------------ --------- 251.7/331.9 MB 1.8 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 251.7/331.9 MB 1.8 MB/s eta 0:00:45\n",
      "   ------------------------------ --------- 252.4/331.9 MB 1.8 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 253.2/331.9 MB 1.8 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 253.5/331.9 MB 1.8 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 254.0/331.9 MB 1.8 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 254.5/331.9 MB 1.8 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 254.5/331.9 MB 1.8 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 254.5/331.9 MB 1.8 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 254.5/331.9 MB 1.8 MB/s eta 0:00:43\n",
      "   ------------------------------ --------- 255.6/331.9 MB 1.8 MB/s eta 0:00:44\n",
      "   ------------------------------ --------- 256.9/331.9 MB 1.8 MB/s eta 0:00:42\n",
      "   ------------------------------ --------- 256.9/331.9 MB 1.8 MB/s eta 0:00:42\n",
      "   ------------------------------- -------- 257.7/331.9 MB 1.8 MB/s eta 0:00:42\n",
      "   ------------------------------- -------- 258.7/331.9 MB 1.8 MB/s eta 0:00:41\n",
      "   ------------------------------- -------- 258.7/331.9 MB 1.8 MB/s eta 0:00:41\n",
      "   ------------------------------- -------- 259.0/331.9 MB 1.8 MB/s eta 0:00:42\n",
      "   ------------------------------- -------- 259.5/331.9 MB 1.8 MB/s eta 0:00:42\n",
      "   ------------------------------- -------- 259.8/331.9 MB 1.8 MB/s eta 0:00:42\n",
      "   ------------------------------- -------- 259.8/331.9 MB 1.8 MB/s eta 0:00:42\n",
      "   ------------------------------- -------- 261.1/331.9 MB 1.7 MB/s eta 0:00:43\n",
      "   ------------------------------- -------- 261.1/331.9 MB 1.7 MB/s eta 0:00:43\n",
      "   ------------------------------- -------- 261.1/331.9 MB 1.7 MB/s eta 0:00:43\n",
      "   ------------------------------- -------- 261.1/331.9 MB 1.7 MB/s eta 0:00:43\n",
      "   ------------------------------- -------- 261.1/331.9 MB 1.7 MB/s eta 0:00:43\n",
      "   ------------------------------- -------- 261.6/331.9 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------------------------- -------- 262.4/331.9 MB 1.5 MB/s eta 0:00:45\n",
      "   ------------------------------- -------- 262.4/331.9 MB 1.5 MB/s eta 0:00:45\n",
      "   ------------------------------- -------- 262.4/331.9 MB 1.5 MB/s eta 0:00:45\n",
      "   ------------------------------- -------- 263.7/331.9 MB 1.5 MB/s eta 0:00:45\n",
      "   ------------------------------- -------- 264.2/331.9 MB 1.5 MB/s eta 0:00:45\n",
      "   ------------------------------- -------- 265.0/331.9 MB 1.5 MB/s eta 0:00:44\n",
      "   -------------------------------- ------- 266.6/331.9 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------------------------- ------- 267.1/331.9 MB 1.6 MB/s eta 0:00:41\n",
      "   -------------------------------- ------- 268.2/331.9 MB 1.6 MB/s eta 0:00:40\n",
      "   -------------------------------- ------- 268.2/331.9 MB 1.6 MB/s eta 0:00:40\n",
      "   -------------------------------- ------- 268.4/331.9 MB 1.6 MB/s eta 0:00:41\n",
      "   -------------------------------- ------- 269.2/331.9 MB 1.6 MB/s eta 0:00:40\n",
      "   -------------------------------- ------- 270.5/331.9 MB 1.6 MB/s eta 0:00:39\n",
      "   -------------------------------- ------- 271.3/331.9 MB 1.6 MB/s eta 0:00:38\n",
      "   -------------------------------- ------- 272.1/331.9 MB 1.6 MB/s eta 0:00:37\n",
      "   -------------------------------- ------- 272.9/331.9 MB 1.6 MB/s eta 0:00:36\n",
      "   --------------------------------- ------ 274.5/331.9 MB 1.7 MB/s eta 0:00:35\n",
      "   --------------------------------- ------ 276.0/331.9 MB 1.7 MB/s eta 0:00:33\n",
      "   --------------------------------- ------ 276.8/331.9 MB 1.7 MB/s eta 0:00:33\n",
      "   --------------------------------- ------ 277.3/331.9 MB 1.7 MB/s eta 0:00:32\n",
      "   --------------------------------- ------ 277.9/331.9 MB 1.7 MB/s eta 0:00:32\n",
      "   --------------------------------- ------ 278.7/331.9 MB 1.7 MB/s eta 0:00:31\n",
      "   --------------------------------- ------ 279.7/331.9 MB 1.8 MB/s eta 0:00:30\n",
      "   --------------------------------- ------ 280.2/331.9 MB 1.8 MB/s eta 0:00:30\n",
      "   --------------------------------- ------ 280.8/331.9 MB 1.8 MB/s eta 0:00:29\n",
      "   --------------------------------- ------ 281.3/331.9 MB 1.8 MB/s eta 0:00:29\n",
      "   --------------------------------- ------ 281.5/331.9 MB 1.8 MB/s eta 0:00:29\n",
      "   --------------------------------- ------ 282.1/331.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ---------------------------------- ----- 282.6/331.9 MB 1.8 MB/s eta 0:00:28\n",
      "   ---------------------------------- ----- 283.1/331.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ---------------------------------- ----- 283.6/331.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ---------------------------------- ----- 284.2/331.9 MB 1.8 MB/s eta 0:00:27\n",
      "   ---------------------------------- ----- 284.7/331.9 MB 1.9 MB/s eta 0:00:26\n",
      "   ---------------------------------- ----- 285.2/331.9 MB 1.9 MB/s eta 0:00:26\n",
      "   ---------------------------------- ----- 285.7/331.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ---------------------------------- ----- 286.5/331.9 MB 1.9 MB/s eta 0:00:25\n",
      "   ---------------------------------- ----- 287.0/331.9 MB 1.9 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 287.6/331.9 MB 1.9 MB/s eta 0:00:24\n",
      "   ---------------------------------- ----- 288.1/331.9 MB 1.9 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 288.4/331.9 MB 1.9 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 288.9/331.9 MB 1.9 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 289.4/331.9 MB 1.9 MB/s eta 0:00:23\n",
      "   ---------------------------------- ----- 289.9/331.9 MB 1.9 MB/s eta 0:00:22\n",
      "   ----------------------------------- ---- 290.5/331.9 MB 1.9 MB/s eta 0:00:22\n",
      "   ----------------------------------- ---- 290.7/331.9 MB 1.9 MB/s eta 0:00:22\n",
      "   ----------------------------------- ---- 291.0/331.9 MB 1.9 MB/s eta 0:00:22\n",
      "   ----------------------------------- ---- 291.5/331.9 MB 1.9 MB/s eta 0:00:21\n",
      "   ----------------------------------- ---- 292.0/331.9 MB 2.0 MB/s eta 0:00:21\n",
      "   ----------------------------------- ---- 292.6/331.9 MB 2.0 MB/s eta 0:00:20\n",
      "   ----------------------------------- ---- 293.1/331.9 MB 2.0 MB/s eta 0:00:20\n",
      "   ----------------------------------- ---- 293.6/331.9 MB 2.0 MB/s eta 0:00:20\n",
      "   ----------------------------------- ---- 294.1/331.9 MB 2.0 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 294.6/331.9 MB 2.0 MB/s eta 0:00:19\n",
      "   ----------------------------------- ---- 295.2/331.9 MB 2.0 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 295.7/331.9 MB 2.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 296.0/331.9 MB 2.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 296.0/331.9 MB 2.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 296.0/331.9 MB 2.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 296.2/331.9 MB 2.0 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 296.5/331.9 MB 2.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 296.7/331.9 MB 2.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 296.7/331.9 MB 2.1 MB/s eta 0:00:18\n",
      "   ----------------------------------- ---- 297.0/331.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 297.3/331.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 297.5/331.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 298.1/331.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 298.3/331.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ----------------------------------- ---- 298.6/331.9 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------------------------ --- 299.1/331.9 MB 2.1 MB/s eta 0:00:16\n",
      "   ------------------------------------ --- 299.6/331.9 MB 2.1 MB/s eta 0:00:16\n",
      "   ------------------------------------ --- 300.2/331.9 MB 2.1 MB/s eta 0:00:16\n",
      "   ------------------------------------ --- 300.2/331.9 MB 2.1 MB/s eta 0:00:16\n",
      "   ------------------------------------ --- 300.7/331.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 301.2/331.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 301.7/331.9 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------------------------ --- 302.5/331.9 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 303.0/331.9 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 303.3/331.9 MB 2.2 MB/s eta 0:00:14\n",
      "   ------------------------------------ --- 303.8/331.9 MB 2.2 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 304.6/331.9 MB 2.2 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 305.1/331.9 MB 2.2 MB/s eta 0:00:13\n",
      "   ------------------------------------ --- 306.2/331.9 MB 2.2 MB/s eta 0:00:12\n",
      "   ------------------------------------ --- 306.7/331.9 MB 2.3 MB/s eta 0:00:12\n",
      "   ------------------------------------- -- 307.2/331.9 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 308.5/331.9 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------------------------- -- 309.3/331.9 MB 2.3 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 310.6/331.9 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------------------------- -- 311.7/331.9 MB 2.4 MB/s eta 0:00:09\n",
      "   ------------------------------------- -- 312.5/331.9 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 313.3/331.9 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 313.8/331.9 MB 2.5 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 314.6/331.9 MB 2.5 MB/s eta 0:00:08\n",
      "   ------------------------------------- -- 314.8/331.9 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 315.4/331.9 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 315.6/331.9 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 315.9/331.9 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 316.1/331.9 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 316.7/331.9 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 316.9/331.9 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------------------- - 317.2/331.9 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 317.7/331.9 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 318.0/331.9 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 318.2/331.9 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 318.5/331.9 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 318.8/331.9 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 318.8/331.9 MB 2.5 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.0/331.9 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.0/331.9 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.3/331.9 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.3/331.9 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.6/331.9 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 319.8/331.9 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------------------------- - 320.1/331.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 320.1/331.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 320.6/331.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 320.9/331.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.1/331.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.1/331.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.1/331.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.4/331.9 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.7/331.9 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 321.9/331.9 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 322.2/331.9 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 322.4/331.9 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 322.7/331.9 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 323.2/331.9 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 323.5/331.9 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  324.0/331.9 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  324.0/331.9 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------------------  324.5/331.9 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------------------  325.1/331.9 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------------------  325.3/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  325.8/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.1/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.1/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.4/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.4/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.6/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.6/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.9/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  326.9/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  327.2/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  327.2/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  327.2/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  327.4/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  327.4/331.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  327.7/331.9 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  327.7/331.9 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  327.9/331.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  327.9/331.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.2/331.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.2/331.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.5/331.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.7/331.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.7/331.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  329.0/331.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  329.3/331.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  329.5/331.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  329.5/331.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  329.8/331.9 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  330.0/331.9 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  330.3/331.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.6/331.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.6/331.9 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.8/331.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.1/331.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.4/331.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.6/331.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.9/331.9 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.75.1-cp312-cp312-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.6 MB 430.4 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 0.5/4.6 MB 430.4 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 0.5/4.6 MB 430.4 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 0.5/4.6 MB 430.4 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 0.8/4.6 MB 385.8 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 0.8/4.6 MB 385.8 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 1.0/4.6 MB 409.2 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.0/4.6 MB 409.2 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.0/4.6 MB 409.2 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.3/4.6 MB 427.5 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 1.3/4.6 MB 427.5 kB/s eta 0:00:08\n",
      "   ------------- -------------------------- 1.6/4.6 MB 451.0 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 1.6/4.6 MB 451.0 kB/s eta 0:00:07\n",
      "   --------------- ------------------------ 1.8/4.6 MB 472.6 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 1.8/4.6 MB 472.6 kB/s eta 0:00:06\n",
      "   ------------------ --------------------- 2.1/4.6 MB 495.5 kB/s eta 0:00:06\n",
      "   ------------------ --------------------- 2.1/4.6 MB 495.5 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 2.4/4.6 MB 514.3 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 2.4/4.6 MB 514.3 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 2.6/4.6 MB 531.7 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 2.6/4.6 MB 531.7 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 2.9/4.6 MB 539.5 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 3.1/4.6 MB 557.5 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 3.1/4.6 MB 557.5 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 3.4/4.6 MB 573.6 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 3.7/4.6 MB 589.5 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.9/4.6 MB 605.4 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.9/4.6 MB 605.4 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 4.2/4.6 MB 619.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.5/4.6 MB 636.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 644.4 kB/s eta 0:00:00\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.4 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.0/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.3/1.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/26.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/26.4 MB 1.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.8/26.4 MB 1.5 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 1.3/26.4 MB 1.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 1.8/26.4 MB 1.8 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 2.4/26.4 MB 1.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 2.0 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 3.4/26.4 MB 2.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.9/26.4 MB 2.1 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.5/26.4 MB 2.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 5.0/26.4 MB 2.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.8/26.4 MB 2.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 6.6/26.4 MB 2.5 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 2.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 2.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 7.9/26.4 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 8.4/26.4 MB 2.4 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 9.4/26.4 MB 2.5 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 10.2/26.4 MB 2.6 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 10.5/26.4 MB 2.6 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 2.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 11.8/26.4 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 12.1/26.4 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 12.3/26.4 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 12.3/26.4 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 12.3/26.4 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.6/26.4 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.6/26.4 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.6/26.4 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.6/26.4 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.6/26.4 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.6/26.4 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.8/26.4 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 12.8/26.4 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 13.1/26.4 MB 1.8 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 13.4/26.4 MB 1.8 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 13.6/26.4 MB 1.8 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 13.6/26.4 MB 1.8 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 14.2/26.4 MB 1.7 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 14.4/26.4 MB 1.7 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 14.7/26.4 MB 1.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 15.2/26.4 MB 1.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 1.8 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 16.3/26.4 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 16.8/26.4 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 17.6/26.4 MB 1.8 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 18.4/26.4 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 19.9/26.4 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 21.0/26.4 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 22.0/26.4 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 23.6/26.4 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 24.9/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.8/5.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.2/5.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, typing_extensions, termcolor, tensorboard-data-server, protobuf, opt_einsum, ml_dtypes, google_pasta, gast, astunparse, absl-py, optree, grpcio, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 keras-3.11.3 libclang-18.1.1 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.32.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 typing_extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.32.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12cb3d94-13cc-4ce7-a812-ad5fdaf5cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Nadam\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee848f8-5e18-49ad-a674-5ac51447de5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.20.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daa3a38d-cc75-4ff1-a902-a6ed45aa450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2018</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2012</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0     Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1     Bachelors         2013       Pune            1   28  Female          No   \n",
       "2     Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3       Masters         2016  Bangalore            3   27    Male          No   \n",
       "4       Masters         2017       Pune            3   24    Male         Yes   \n",
       "...         ...          ...        ...          ...  ...     ...         ...   \n",
       "4648  Bachelors         2013  Bangalore            3   26  Female          No   \n",
       "4649    Masters         2013       Pune            2   37    Male          No   \n",
       "4650    Masters         2018  New Delhi            3   27    Male          No   \n",
       "4651  Bachelors         2012  Bangalore            3   30    Male         Yes   \n",
       "4652  Bachelors         2015  Bangalore            3   33    Male         Yes   \n",
       "\n",
       "      ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                             0           0  \n",
       "1                             3           1  \n",
       "2                             2           0  \n",
       "3                             5           1  \n",
       "4                             2           1  \n",
       "...                         ...         ...  \n",
       "4648                          4           0  \n",
       "4649                          2           1  \n",
       "4650                          5           1  \n",
       "4651                          2           0  \n",
       "4652                          4           0  \n",
       "\n",
       "[4653 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Employee.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9ebcce-4d37-4ee8-9ec0-5a1a953fb801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4653</td>\n",
       "      <td>4653.000000</td>\n",
       "      <td>4653</td>\n",
       "      <td>4653.000000</td>\n",
       "      <td>4653.000000</td>\n",
       "      <td>4653</td>\n",
       "      <td>4653</td>\n",
       "      <td>4653.000000</td>\n",
       "      <td>4653.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2778</td>\n",
       "      <td>4175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.062970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.698259</td>\n",
       "      <td>29.393295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.905652</td>\n",
       "      <td>0.343864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.863377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.561435</td>\n",
       "      <td>4.826087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.558240</td>\n",
       "      <td>0.475047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Education  JoiningYear       City  PaymentTier          Age Gender  \\\n",
       "count        4653  4653.000000       4653  4653.000000  4653.000000   4653   \n",
       "unique          3          NaN          3          NaN          NaN      2   \n",
       "top     Bachelors          NaN  Bangalore          NaN          NaN   Male   \n",
       "freq         3601          NaN       2228          NaN          NaN   2778   \n",
       "mean          NaN  2015.062970        NaN     2.698259    29.393295    NaN   \n",
       "std           NaN     1.863377        NaN     0.561435     4.826087    NaN   \n",
       "min           NaN  2012.000000        NaN     1.000000    22.000000    NaN   \n",
       "25%           NaN  2013.000000        NaN     3.000000    26.000000    NaN   \n",
       "50%           NaN  2015.000000        NaN     3.000000    28.000000    NaN   \n",
       "75%           NaN  2017.000000        NaN     3.000000    32.000000    NaN   \n",
       "max           NaN  2018.000000        NaN     3.000000    41.000000    NaN   \n",
       "\n",
       "       EverBenched  ExperienceInCurrentDomain   LeaveOrNot  \n",
       "count         4653                4653.000000  4653.000000  \n",
       "unique           2                        NaN          NaN  \n",
       "top             No                        NaN          NaN  \n",
       "freq          4175                        NaN          NaN  \n",
       "mean           NaN                   2.905652     0.343864  \n",
       "std            NaN                   1.558240     0.475047  \n",
       "min            NaN                   0.000000     0.000000  \n",
       "25%            NaN                   2.000000     0.000000  \n",
       "50%            NaN                   3.000000     0.000000  \n",
       "75%            NaN                   4.000000     1.000000  \n",
       "max            NaN                   7.000000     1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301f2e02-2cd5-46b0-b720-bbc901229a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education                    0\n",
       "JoiningYear                  0\n",
       "City                         0\n",
       "PaymentTier                  0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "EverBenched                  0\n",
       "ExperienceInCurrentDomain    0\n",
       "LeaveOrNot                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14cb8e16-e6f5-4872-b285-70cd482d71e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  LeaveOrNot  \\\n",
       "0            2017            3   34                          0           0   \n",
       "1            2013            1   28                          3           1   \n",
       "2            2014            3   38                          2           0   \n",
       "3            2016            3   27                          5           1   \n",
       "4            2017            3   24                          2           1   \n",
       "...           ...          ...  ...                        ...         ...   \n",
       "4648         2013            3   26                          4           0   \n",
       "4649         2013            2   37                          2           1   \n",
       "4650         2018            3   27                          5           1   \n",
       "4651         2012            3   30                          2           0   \n",
       "4652         2015            3   33                          4           0   \n",
       "\n",
       "      Education_Masters  Education_PHD  City_New Delhi  City_Pune  \\\n",
       "0                 False          False           False      False   \n",
       "1                 False          False           False       True   \n",
       "2                 False          False            True      False   \n",
       "3                  True          False           False      False   \n",
       "4                  True          False           False       True   \n",
       "...                 ...            ...             ...        ...   \n",
       "4648              False          False           False      False   \n",
       "4649               True          False           False       True   \n",
       "4650               True          False            True      False   \n",
       "4651              False          False           False      False   \n",
       "4652              False          False           False      False   \n",
       "\n",
       "      Gender_Male  EverBenched_Yes  \n",
       "0            True            False  \n",
       "1           False            False  \n",
       "2           False            False  \n",
       "3            True            False  \n",
       "4            True             True  \n",
       "...           ...              ...  \n",
       "4648        False            False  \n",
       "4649         True            False  \n",
       "4650         True            False  \n",
       "4651         True             True  \n",
       "4652         True             True  \n",
       "\n",
       "[4653 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00382cfc-4b09-4be5-93f1-1e567fb1675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data['LeaveOrNot']\n",
    "\n",
    "inputs = data.drop(['LeaveOrNot'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96aa098d-93f7-46eb-b55a-824d617004b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.039638</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.954645</td>\n",
       "      <td>-1.864901</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.107233</td>\n",
       "      <td>-3.025177</td>\n",
       "      <td>-0.288732</td>\n",
       "      <td>0.060554</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>1.633878</td>\n",
       "      <td>-1.217210</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.570515</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>1.783563</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>1.738277</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>-1.217210</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.502921</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>-0.495961</td>\n",
       "      <td>1.344191</td>\n",
       "      <td>2.080840</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.039638</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>-1.117650</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>2.080840</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>1.633878</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>2.955387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>-1.107233</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>-0.703191</td>\n",
       "      <td>0.702373</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>-1.217210</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>-1.107233</td>\n",
       "      <td>-1.243837</td>\n",
       "      <td>1.576334</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>2.080840</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>1.633878</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>1.576356</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>-0.495961</td>\n",
       "      <td>1.344191</td>\n",
       "      <td>2.080840</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>1.738277</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>-0.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>-1.643951</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.125727</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>2.955387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>-0.033797</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.747416</td>\n",
       "      <td>0.702373</td>\n",
       "      <td>-0.480575</td>\n",
       "      <td>-0.200022</td>\n",
       "      <td>-0.575282</td>\n",
       "      <td>-0.612041</td>\n",
       "      <td>0.821551</td>\n",
       "      <td>2.955387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      JoiningYear  PaymentTier       Age  ExperienceInCurrentDomain  \\\n",
       "0        1.039638     0.537503  0.954645                  -1.864901   \n",
       "1       -1.107233    -3.025177 -0.288732                   0.060554   \n",
       "2       -0.570515     0.537503  1.783563                  -0.581264   \n",
       "3        0.502921     0.537503 -0.495961                   1.344191   \n",
       "4        1.039638     0.537503 -1.117650                  -0.581264   \n",
       "...           ...          ...       ...                        ...   \n",
       "4648    -1.107233     0.537503 -0.703191                   0.702373   \n",
       "4649    -1.107233    -1.243837  1.576334                  -0.581264   \n",
       "4650     1.576356     0.537503 -0.495961                   1.344191   \n",
       "4651    -1.643951     0.537503  0.125727                  -0.581264   \n",
       "4652    -0.033797     0.537503  0.747416                   0.702373   \n",
       "\n",
       "      Education_Masters  Education_PHD  City_New Delhi  City_Pune  \\\n",
       "0             -0.480575      -0.200022       -0.575282  -0.612041   \n",
       "1             -0.480575      -0.200022       -0.575282   1.633878   \n",
       "2             -0.480575      -0.200022        1.738277  -0.612041   \n",
       "3              2.080840      -0.200022       -0.575282  -0.612041   \n",
       "4              2.080840      -0.200022       -0.575282   1.633878   \n",
       "...                 ...            ...             ...        ...   \n",
       "4648          -0.480575      -0.200022       -0.575282  -0.612041   \n",
       "4649           2.080840      -0.200022       -0.575282   1.633878   \n",
       "4650           2.080840      -0.200022        1.738277  -0.612041   \n",
       "4651          -0.480575      -0.200022       -0.575282  -0.612041   \n",
       "4652          -0.480575      -0.200022       -0.575282  -0.612041   \n",
       "\n",
       "      Gender_Male  EverBenched_Yes  \n",
       "0        0.821551        -0.338365  \n",
       "1       -1.217210        -0.338365  \n",
       "2       -1.217210        -0.338365  \n",
       "3        0.821551        -0.338365  \n",
       "4        0.821551         2.955387  \n",
       "...           ...              ...  \n",
       "4648    -1.217210        -0.338365  \n",
       "4649     0.821551        -0.338365  \n",
       "4650     0.821551        -0.338365  \n",
       "4651     0.821551         2.955387  \n",
       "4652     0.821551         2.955387  \n",
       "\n",
       "[4653 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(inputs)\n",
    "\n",
    "scaled = scaler.transform(inputs)\n",
    "\n",
    "inputs_scaled = pd.DataFrame(scaled, columns=inputs.columns)\n",
    "\n",
    "inputs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1bbb98a-260c-459a-a616-04f1a29b670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs_scaled, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fb6e1e5-a8c9-42c0-be82-d1f5dc21e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    # Building artificial neural network\n",
    "    model = Sequential()\n",
    "\n",
    "     # we add 2 hidden layers and 1 output layer\n",
    "    model.add(Dense(units=trial.suggest_int('units_layer1', 6, 32), activation='relu'))\n",
    "    model.add(Dense(units=trial.suggest_int('units_layer2', 6, 32), activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Suggest hyperparameters for the optimizer\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop', 'adagrad'])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    \n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'adagrad':\n",
    "        optimizer = Adagrad(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346225d0-bd2b-417f-9229-3410743d7fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:22:43,221] A new study created in memory with name: no-name-42d626ce-d30f-4e2b-9bdc-2a05f10a47f0\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.5310 - loss: 0.6883\n",
      "Epoch 2/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5532 - loss: 0.6800\n",
      "Epoch 3/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5718 - loss: 0.6724\n",
      "Epoch 4/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5908 - loss: 0.6651\n",
      "Epoch 5/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6054 - loss: 0.6582\n",
      "Epoch 6/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6190 - loss: 0.6519\n",
      "Epoch 7/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6308 - loss: 0.6458 \n",
      "Epoch 8/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6415 - loss: 0.6401\n",
      "Epoch 9/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6519 - loss: 0.6345\n",
      "Epoch 10/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6612 - loss: 0.6293\n",
      "Epoch 11/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6691 - loss: 0.6244\n",
      "Epoch 12/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6769 - loss: 0.6198\n",
      "Epoch 13/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6836 - loss: 0.6155\n",
      "Epoch 14/14\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6896 - loss: 0.6115\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:22:48,565] Trial 0 finished with value: 0.724901690414177 and parameters: {'epochs': 14, 'batch_size': 33, 'units_layer1': 28, 'units_layer2': 9, 'optimizer': 'adam', 'learning_rate': 5.013988358641449e-05}. Best is trial 0 with value: 0.724901690414177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.6062 - loss: 0.7088  \n",
      "Epoch 2/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7204 - loss: 0.5851\n",
      "Epoch 3/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7530 - loss: 0.5461\n",
      "Epoch 4/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7679 - loss: 0.5239\n",
      "Epoch 5/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7832 - loss: 0.5072\n",
      "Epoch 6/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7961 - loss: 0.4927\n",
      "Epoch 7/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8045 - loss: 0.4816\n",
      "Epoch 8/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8128 - loss: 0.4715\n",
      "Epoch 9/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8201 - loss: 0.4628\n",
      "Epoch 10/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8259 - loss: 0.4556\n",
      "Epoch 11/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8315 - loss: 0.4479\n",
      "Epoch 12/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8358 - loss: 0.4411\n",
      "Epoch 13/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8383 - loss: 0.4351 \n",
      "Epoch 14/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8421 - loss: 0.4294\n",
      "Epoch 15/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8459 - loss: 0.4238\n",
      "Epoch 16/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8482 - loss: 0.4189 \n",
      "Epoch 17/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8511 - loss: 0.4147 \n",
      "Epoch 18/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8530 - loss: 0.4107\n",
      "Epoch 19/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8546 - loss: 0.4066\n",
      "Epoch 20/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8573 - loss: 0.4032\n",
      "Epoch 21/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8579 - loss: 0.4002\n",
      "Epoch 22/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8597 - loss: 0.3969\n",
      "Epoch 23/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8615 - loss: 0.3944\n",
      "Epoch 24/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8639 - loss: 0.3918\n",
      "Epoch 25/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8639 - loss: 0.3897\n",
      "Epoch 26/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8651 - loss: 0.3874\n",
      "Epoch 27/27\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8670 - loss: 0.3846\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:22:54,800] Trial 1 finished with value: 0.8856084980338084 and parameters: {'epochs': 27, 'batch_size': 45, 'units_layer1': 20, 'units_layer2': 20, 'optimizer': 'rmsprop', 'learning_rate': 0.0009430278568201369}. Best is trial 1 with value: 0.8856084980338084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.6520 - loss: 0.7430\n",
      "Epoch 2/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6763 - loss: 0.6715\n",
      "Epoch 3/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7004 - loss: 0.6321\n",
      "Epoch 4/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7168 - loss: 0.6063\n",
      "Epoch 5/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7322 - loss: 0.5875\n",
      "Epoch 6/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7440 - loss: 0.5730\n",
      "Epoch 7/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7484 - loss: 0.5618\n",
      "Epoch 8/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7538 - loss: 0.5531\n",
      "Epoch 9/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7579 - loss: 0.5464\n",
      "Epoch 10/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7615 - loss: 0.5409\n",
      "Epoch 11/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7645 - loss: 0.5364\n",
      "Epoch 12/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7675 - loss: 0.5325\n",
      "Epoch 13/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7710 - loss: 0.5290\n",
      "Epoch 14/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7737 - loss: 0.5258\n",
      "Epoch 15/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7760 - loss: 0.5229\n",
      "Epoch 16/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7784 - loss: 0.5201\n",
      "Epoch 17/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7805 - loss: 0.5175\n",
      "Epoch 18/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7825 - loss: 0.5151\n",
      "Epoch 19/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7847 - loss: 0.5125\n",
      "Epoch 20/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7867 - loss: 0.5102\n",
      "Epoch 21/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7888 - loss: 0.5079 \n",
      "Epoch 22/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7902 - loss: 0.5058\n",
      "Epoch 23/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7922 - loss: 0.5036\n",
      "Epoch 24/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7941 - loss: 0.5015\n",
      "Epoch 25/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7960 - loss: 0.4993\n",
      "Epoch 26/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7975 - loss: 0.4972 \n",
      "Epoch 27/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7994 - loss: 0.4952\n",
      "Epoch 28/28\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8011 - loss: 0.4933\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:23:01,025] Trial 2 finished with value: 0.836675859251315 and parameters: {'epochs': 28, 'batch_size': 46, 'units_layer1': 32, 'units_layer2': 31, 'optimizer': 'adam', 'learning_rate': 0.00010973648536295668}. Best is trial 1 with value: 0.8856084980338084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.4841 - loss: 0.7780 \n",
      "Epoch 2/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4841 - loss: 0.7776\n",
      "Epoch 3/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4844 - loss: 0.7772\n",
      "Epoch 4/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4844 - loss: 0.7769\n",
      "Epoch 5/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4847 - loss: 0.7767\n",
      "Epoch 6/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4848 - loss: 0.7764\n",
      "Epoch 7/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4847 - loss: 0.7762\n",
      "Epoch 8/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4847 - loss: 0.7760\n",
      "Epoch 9/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4843 - loss: 0.7758\n",
      "Epoch 10/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4842 - loss: 0.7757\n",
      "Epoch 11/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4841 - loss: 0.7755\n",
      "Epoch 12/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4842 - loss: 0.7753\n",
      "Epoch 13/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4840 - loss: 0.7752\n",
      "Epoch 14/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4840 - loss: 0.7750\n",
      "Epoch 15/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4841 - loss: 0.7749\n",
      "Epoch 16/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4842 - loss: 0.7748\n",
      "Epoch 17/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4840 - loss: 0.7746\n",
      "Epoch 18/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4840 - loss: 0.7745\n",
      "Epoch 19/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4841 - loss: 0.7744\n",
      "Epoch 20/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4839 - loss: 0.7742\n",
      "Epoch 21/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4840 - loss: 0.7741\n",
      "Epoch 22/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4842 - loss: 0.7740\n",
      "Epoch 23/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4842 - loss: 0.7739\n",
      "Epoch 24/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4840 - loss: 0.7738\n",
      "Epoch 25/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4838 - loss: 0.7737\n",
      "Epoch 26/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4838 - loss: 0.7736\n",
      "Epoch 27/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4838 - loss: 0.7734\n",
      "Epoch 28/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4839 - loss: 0.7733\n",
      "Epoch 29/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4838 - loss: 0.7732\n",
      "Epoch 30/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4838 - loss: 0.7731\n",
      "Epoch 31/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4838 - loss: 0.7730\n",
      "Epoch 32/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4838 - loss: 0.7729\n",
      "Epoch 33/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4839 - loss: 0.7728\n",
      "Epoch 34/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4840 - loss: 0.7728\n",
      "Epoch 35/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4840 - loss: 0.7727\n",
      "Epoch 36/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4842 - loss: 0.7726\n",
      "Epoch 37/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4841 - loss: 0.7725\n",
      "Epoch 38/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4842 - loss: 0.7724\n",
      "Epoch 39/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4842 - loss: 0.7723\n",
      "Epoch 40/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4842 - loss: 0.7722\n",
      "Epoch 41/41\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4843 - loss: 0.7721\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:23:10,832] Trial 3 finished with value: 0.44978295286246867 and parameters: {'epochs': 41, 'batch_size': 32, 'units_layer1': 20, 'units_layer2': 16, 'optimizer': 'adagrad', 'learning_rate': 1.0944554801285036e-05}. Best is trial 1 with value: 0.8856084980338084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.4657 - loss: 0.7489  \n",
      "Epoch 2/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4696 - loss: 0.7442\n",
      "Epoch 3/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4726 - loss: 0.7407\n",
      "Epoch 4/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4758 - loss: 0.7378\n",
      "Epoch 5/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4773 - loss: 0.7352\n",
      "Epoch 6/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4799 - loss: 0.7329\n",
      "Epoch 7/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4819 - loss: 0.7309\n",
      "Epoch 8/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4834 - loss: 0.7290\n",
      "Epoch 9/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4858 - loss: 0.7272\n",
      "Epoch 10/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4875 - loss: 0.7256\n",
      "Epoch 11/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4893 - loss: 0.7240\n",
      "Epoch 12/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4907 - loss: 0.7225\n",
      "Epoch 13/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4917 - loss: 0.7211\n",
      "Epoch 14/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4938 - loss: 0.7198\n",
      "Epoch 15/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4947 - loss: 0.7185\n",
      "Epoch 16/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4963 - loss: 0.7173\n",
      "Epoch 17/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4978 - loss: 0.7161\n",
      "Epoch 18/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4986 - loss: 0.7150\n",
      "Epoch 19/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4995 - loss: 0.7139\n",
      "Epoch 20/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5008 - loss: 0.7129\n",
      "Epoch 21/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5020 - loss: 0.7119\n",
      "Epoch 22/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5028 - loss: 0.7109\n",
      "Epoch 23/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5038 - loss: 0.7100\n",
      "Epoch 24/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.5049 - loss: 0.7091\n",
      "Epoch 25/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5062 - loss: 0.7082\n",
      "Epoch 26/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5073 - loss: 0.7073\n",
      "Epoch 27/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5078 - loss: 0.7065\n",
      "Epoch 28/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5089 - loss: 0.7057\n",
      "Epoch 29/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5095 - loss: 0.7049\n",
      "Epoch 30/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5104 - loss: 0.7041\n",
      "Epoch 31/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5114 - loss: 0.7033\n",
      "Epoch 32/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5118 - loss: 0.7026\n",
      "Epoch 33/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5127 - loss: 0.7019\n",
      "Epoch 34/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5134 - loss: 0.7012\n",
      "Epoch 35/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5144 - loss: 0.7005\n",
      "Epoch 36/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5148 - loss: 0.6998\n",
      "Epoch 37/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5155 - loss: 0.6991\n",
      "Epoch 38/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5163 - loss: 0.6985\n",
      "Epoch 39/39\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5169 - loss: 0.6978  \n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:23:18,539] Trial 4 finished with value: 0.4855446606404167 and parameters: {'epochs': 39, 'batch_size': 47, 'units_layer1': 21, 'units_layer2': 9, 'optimizer': 'adagrad', 'learning_rate': 0.00017111707347713595}. Best is trial 1 with value: 0.8856084980338084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.4624 - loss: 0.6747  \n",
      "Epoch 2/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6209 - loss: 0.6252\n",
      "Epoch 3/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6897 - loss: 0.5952\n",
      "Epoch 4/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7195 - loss: 0.5733\n",
      "Epoch 5/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7380 - loss: 0.5560\n",
      "Epoch 6/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7557 - loss: 0.5410\n",
      "Epoch 7/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7699 - loss: 0.5282\n",
      "Epoch 8/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7808 - loss: 0.5171\n",
      "Epoch 9/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7888 - loss: 0.5088\n",
      "Epoch 10/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7943 - loss: 0.5015\n",
      "Epoch 11/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8000 - loss: 0.4949\n",
      "Epoch 12/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8042 - loss: 0.4893\n",
      "Epoch 13/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8086 - loss: 0.4842\n",
      "Epoch 14/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8115 - loss: 0.4798\n",
      "Epoch 15/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8144 - loss: 0.4760\n",
      "Epoch 16/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8184 - loss: 0.4721\n",
      "Epoch 17/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8205 - loss: 0.4686\n",
      "Epoch 18/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8228 - loss: 0.4655\n",
      "Epoch 19/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8252 - loss: 0.4624\n",
      "Epoch 20/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8261 - loss: 0.4601\n",
      "Epoch 21/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8295 - loss: 0.4571\n",
      "Epoch 22/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8310 - loss: 0.4546\n",
      "Epoch 23/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8325 - loss: 0.4523\n",
      "Epoch 24/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8334 - loss: 0.4500\n",
      "Epoch 25/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8354 - loss: 0.4475\n",
      "Epoch 26/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8365 - loss: 0.4456\n",
      "Epoch 27/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8377 - loss: 0.4435\n",
      "Epoch 28/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8391 - loss: 0.4416\n",
      "Epoch 29/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8411 - loss: 0.4395\n",
      "Epoch 30/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.8411 - loss: 0.4380\n",
      "Epoch 31/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8420 - loss: 0.4363\n",
      "Epoch 32/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8429 - loss: 0.4349\n",
      "Epoch 33/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8449 - loss: 0.4330\n",
      "Epoch 34/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8437 - loss: 0.4323\n",
      "Epoch 35/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8452 - loss: 0.4304\n",
      "Epoch 36/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8455 - loss: 0.4289\n",
      "Epoch 37/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8463 - loss: 0.4279\n",
      "Epoch 38/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8471 - loss: 0.4265\n",
      "Epoch 39/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8477 - loss: 0.4253\n",
      "Epoch 40/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8493 - loss: 0.4233\n",
      "Epoch 41/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8494 - loss: 0.4220\n",
      "Epoch 42/42\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8497 - loss: 0.4208\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:23:25,116] Trial 5 finished with value: 0.8697921454471171 and parameters: {'epochs': 42, 'batch_size': 64, 'units_layer1': 10, 'units_layer2': 30, 'optimizer': 'rmsprop', 'learning_rate': 0.0007648796557230679}. Best is trial 1 with value: 0.8856084980338084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - AUC: 0.5943 - loss: 0.6472\n",
      "Epoch 2/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6602 - loss: 0.6146\n",
      "Epoch 3/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6890 - loss: 0.5986\n",
      "Epoch 4/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7057 - loss: 0.5881\n",
      "Epoch 5/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7166 - loss: 0.5798\n",
      "Epoch 6/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7274 - loss: 0.5726\n",
      "Epoch 7/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7355 - loss: 0.5662\n",
      "Epoch 8/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7433 - loss: 0.5601\n",
      "Epoch 9/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7502 - loss: 0.5545\n",
      "Epoch 10/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7563 - loss: 0.5492\n",
      "Epoch 11/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7617 - loss: 0.5441\n",
      "Epoch 12/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7665 - loss: 0.5394\n",
      "Epoch 13/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7711 - loss: 0.5350\n",
      "Epoch 14/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7747 - loss: 0.5307\n",
      "Epoch 15/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7792 - loss: 0.5268\n",
      "Epoch 16/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7823 - loss: 0.5232\n",
      "Epoch 17/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7857 - loss: 0.5200\n",
      "Epoch 18/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7888 - loss: 0.5168\n",
      "Epoch 19/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7910 - loss: 0.5139\n",
      "Epoch 20/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7935 - loss: 0.5113\n",
      "Epoch 21/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7957 - loss: 0.5089\n",
      "Epoch 22/22\n",
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7973 - loss: 0.5067\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:23:32,186] Trial 6 finished with value: 0.8354501812981973 and parameters: {'epochs': 22, 'batch_size': 22, 'units_layer1': 11, 'units_layer2': 22, 'optimizer': 'adagrad', 'learning_rate': 0.007095202037077428}. Best is trial 1 with value: 0.8856084980338084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - AUC: 0.4724 - loss: 0.7997\n",
      "Epoch 2/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4728 - loss: 0.7951\n",
      "Epoch 3/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4720 - loss: 0.7907\n",
      "Epoch 4/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4732 - loss: 0.7865\n",
      "Epoch 5/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4733 - loss: 0.7824\n",
      "Epoch 6/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4731 - loss: 0.7784\n",
      "Epoch 7/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4738 - loss: 0.7745\n",
      "Epoch 8/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4738 - loss: 0.7707\n",
      "Epoch 9/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4741 - loss: 0.7671\n",
      "Epoch 10/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4751 - loss: 0.7636\n",
      "Epoch 11/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4748 - loss: 0.7602\n",
      "Epoch 12/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4756 - loss: 0.7568\n",
      "Epoch 13/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4757 - loss: 0.7536\n",
      "Epoch 14/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4783 - loss: 0.7504\n",
      "Epoch 15/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4805 - loss: 0.7473\n",
      "Epoch 16/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4794 - loss: 0.7443\n",
      "Epoch 17/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4825 - loss: 0.7414\n",
      "Epoch 18/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4833 - loss: 0.7386\n",
      "Epoch 19/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4842 - loss: 0.7358\n",
      "Epoch 20/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4867 - loss: 0.7330\n",
      "Epoch 21/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4884 - loss: 0.7304\n",
      "Epoch 22/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4899 - loss: 0.7278\n",
      "Epoch 23/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4926 - loss: 0.7252\n",
      "Epoch 24/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.4949 - loss: 0.7228\n",
      "Epoch 25/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4985 - loss: 0.7203\n",
      "Epoch 26/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.4982 - loss: 0.7180\n",
      "Epoch 27/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5016 - loss: 0.7156\n",
      "Epoch 28/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5045 - loss: 0.7134\n",
      "Epoch 29/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5087 - loss: 0.7111\n",
      "Epoch 30/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5117 - loss: 0.7089\n",
      "Epoch 31/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5137 - loss: 0.7068\n",
      "Epoch 32/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5187 - loss: 0.7046\n",
      "Epoch 33/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5229 - loss: 0.7026\n",
      "Epoch 34/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5241 - loss: 0.7005\n",
      "Epoch 35/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5288 - loss: 0.6985\n",
      "Epoch 36/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5315 - loss: 0.6965\n",
      "Epoch 37/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5347 - loss: 0.6946\n",
      "Epoch 38/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5399 - loss: 0.6926\n",
      "Epoch 39/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5432 - loss: 0.6907\n",
      "Epoch 40/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5464 - loss: 0.6889\n",
      "Epoch 41/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5520 - loss: 0.6870\n",
      "Epoch 42/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5555 - loss: 0.6852\n",
      "Epoch 43/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5588 - loss: 0.6834\n",
      "Epoch 44/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5616 - loss: 0.6816\n",
      "Epoch 45/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.5663 - loss: 0.6799\n",
      "Epoch 46/46\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5705 - loss: 0.6781\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:23:41,788] Trial 7 finished with value: 0.620004085593177 and parameters: {'epochs': 46, 'batch_size': 42, 'units_layer1': 8, 'units_layer2': 7, 'optimizer': 'adam', 'learning_rate': 2.3119402777034517e-05}. Best is trial 1 with value: 0.8856084980338084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.5104 - loss: 0.6980\n",
      "Epoch 2/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5443 - loss: 0.6767\n",
      "Epoch 3/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.5775 - loss: 0.6603\n",
      "Epoch 4/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6063 - loss: 0.6456\n",
      "Epoch 5/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6251 - loss: 0.6329\n",
      "Epoch 6/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6434 - loss: 0.6218\n",
      "Epoch 7/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6563 - loss: 0.6135\n",
      "Epoch 8/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6677 - loss: 0.6072\n",
      "Epoch 9/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6781 - loss: 0.6019\n",
      "Epoch 10/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.6881 - loss: 0.5974\n",
      "Epoch 11/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.6963 - loss: 0.5933\n",
      "Epoch 12/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7038 - loss: 0.5896\n",
      "Epoch 13/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7101 - loss: 0.5862\n",
      "Epoch 14/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7153 - loss: 0.5833\n",
      "Epoch 15/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7207 - loss: 0.5803\n",
      "Epoch 16/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7253 - loss: 0.5775\n",
      "Epoch 17/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7293 - loss: 0.5748\n",
      "Epoch 18/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7333 - loss: 0.5721\n",
      "Epoch 19/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7369 - loss: 0.5695\n",
      "Epoch 20/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7405 - loss: 0.5669\n",
      "Epoch 21/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7443 - loss: 0.5644\n",
      "Epoch 22/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7473 - loss: 0.5619\n",
      "Epoch 23/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7507 - loss: 0.5595\n",
      "Epoch 24/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.7527 - loss: 0.5570\n",
      "Epoch 25/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7562 - loss: 0.5545\n",
      "Epoch 26/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7585 - loss: 0.5521\n",
      "Epoch 27/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7610 - loss: 0.5498\n",
      "Epoch 28/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7635 - loss: 0.5474\n",
      "Epoch 29/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7660 - loss: 0.5451\n",
      "Epoch 30/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7682 - loss: 0.5427\n",
      "Epoch 31/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7704 - loss: 0.5403\n",
      "Epoch 32/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7726 - loss: 0.5378\n",
      "Epoch 33/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.7745 - loss: 0.5353\n",
      "Epoch 34/34\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - AUC: 0.7763 - loss: 0.5328\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:23:47,877] Trial 8 finished with value: 0.8161993769470405 and parameters: {'epochs': 34, 'batch_size': 58, 'units_layer1': 29, 'units_layer2': 6, 'optimizer': 'adam', 'learning_rate': 0.0001549624580836718}. Best is trial 1 with value: 0.8856084980338084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18584\\3644950783.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.7571 - loss: 0.5387\n",
      "Epoch 2/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8167 - loss: 0.4687\n",
      "Epoch 3/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8371 - loss: 0.4374\n",
      "Epoch 4/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8510 - loss: 0.4149\n",
      "Epoch 5/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8571 - loss: 0.4006\n",
      "Epoch 6/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8617 - loss: 0.3912\n",
      "Epoch 7/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8657 - loss: 0.3851\n",
      "Epoch 8/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8683 - loss: 0.3789\n",
      "Epoch 9/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8711 - loss: 0.3756\n",
      "Epoch 10/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8742 - loss: 0.3731\n",
      "Epoch 11/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8712 - loss: 0.3725\n",
      "Epoch 12/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8734 - loss: 0.3701\n",
      "Epoch 13/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8718 - loss: 0.3672\n",
      "Epoch 14/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8745 - loss: 0.3650\n",
      "Epoch 15/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8771 - loss: 0.3654\n",
      "Epoch 16/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8784 - loss: 0.3616\n",
      "Epoch 17/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8776 - loss: 0.3618\n",
      "Epoch 18/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8790 - loss: 0.3590\n",
      "Epoch 19/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8805 - loss: 0.3573\n",
      "Epoch 20/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8780 - loss: 0.3574\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-27 12:23:55,780] Trial 9 finished with value: 0.8928374444614677 and parameters: {'epochs': 20, 'batch_size': 16, 'units_layer1': 16, 'units_layer2': 29, 'optimizer': 'rmsprop', 'learning_rate': 0.004393941727938682}. Best is trial 9 with value: 0.8928374444614677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0.8928374444614677\n",
      "Best hyperparameters: {'epochs': 20, 'batch_size': 16, 'units_layer1': 16, 'units_layer2': 29, 'optimizer': 'rmsprop', 'learning_rate': 0.004393941727938682}\n"
     ]
    }
   ],
   "source": [
    "def optimal(trial):\n",
    "    \n",
    "    # Suggest the number of epochs and batch size\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "    \n",
    "    model = create_model(trial)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimal, n_trials=10)\n",
    "\n",
    "print(f\"Best trial: {study.best_trial.value}\")\n",
    "print(f\"Best hyperparameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de1373c6-b4b4-4f12-a4b8-ac352e34725a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 20,\n",
       " 'batch_size': 16,\n",
       " 'units_layer1': 16,\n",
       " 'units_layer2': 29,\n",
       " 'optimizer': 'rmsprop',\n",
       " 'learning_rate': 0.004393941727938682}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd5a1e47-12c4-400f-8e3f-08c833123169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "\n",
    "best_model = Sequential()\n",
    "best_model.add(Dense(units=best_params['units_layer1'], activation='relu'))\n",
    "best_model.add(Dense(units=best_params['units_layer2'], activation='relu'))\n",
    "best_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56660b08-eefb-43bb-b058-c66e8df90eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_params['optimizer'] == 'adam':\n",
    "    best_optimizer = Adam(learning_rate=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'sgd':\n",
    "    best_optimizer = SGD(learning_rate=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'rmsprop':\n",
    "    best_optimizer = RMSprop(learning_rate=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'adagrad':\n",
    "    best_optimizer = Adagrad(learning_rate=best_params['learning_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c41ab70e-17dd-4950-9aab-628412fe411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.compile(optimizer=best_optimizer, loss='binary_crossentropy', metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b4746bd-5b19-4cbb-a4d2-b17c0d322577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'])\n",
    "    \n",
    "    '''Predictions and probabilities for the training set'''\n",
    "    \n",
    "    y_train_prob = model.predict(X_train)\n",
    "\n",
    "    '''Predictions and probabilities for the test set'''\n",
    "    \n",
    "    y_test_prob = model.predict(X_test)\n",
    "\n",
    "    '''Calculate metrics for the training set''' \n",
    "    \n",
    "    roc_train_prob = roc_auc_score(y_train, y_train_prob)\n",
    "    gini_train_prob = roc_train_prob * 2 - 1\n",
    "    \n",
    "\n",
    "    '''Calculate metrics for the test set'''\n",
    "    \n",
    "    roc_test_prob = roc_auc_score(y_test, y_test_prob)\n",
    "    gini_test_prob = roc_test_prob * 2 - 1\n",
    "    \n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Dataset': ['Train', 'Test'],\n",
    "        'Gini': [gini_train_prob * 100, gini_test_prob * 100],\n",
    "    \n",
    "    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72a31733-7edd-4ace-a543-b01a63ca3347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.7604 - loss: 0.5371\n",
      "Epoch 2/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8199 - loss: 0.4673\n",
      "Epoch 3/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8407 - loss: 0.4287\n",
      "Epoch 4/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8534 - loss: 0.4100\n",
      "Epoch 5/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8608 - loss: 0.3969\n",
      "Epoch 6/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8604 - loss: 0.3919\n",
      "Epoch 7/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8639 - loss: 0.3849\n",
      "Epoch 8/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8658 - loss: 0.3808\n",
      "Epoch 9/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8723 - loss: 0.3786\n",
      "Epoch 10/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8708 - loss: 0.3747\n",
      "Epoch 11/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8697 - loss: 0.3750\n",
      "Epoch 12/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8707 - loss: 0.3753\n",
      "Epoch 13/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8733 - loss: 0.3738\n",
      "Epoch 14/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8738 - loss: 0.3691\n",
      "Epoch 15/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8757 - loss: 0.3690\n",
      "Epoch 16/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8753 - loss: 0.3680\n",
      "Epoch 17/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - AUC: 0.8754 - loss: 0.3674\n",
      "Epoch 18/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8768 - loss: 0.3656\n",
      "Epoch 19/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - AUC: 0.8752 - loss: 0.3646\n",
      "Epoch 20/20\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - AUC: 0.8775 - loss: 0.3626\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>77.032814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>78.316736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset       Gini\n",
       "0   Train  77.032814\n",
       "1    Test  78.316736"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(best_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e655f3c-499a-42eb-8b38-33b12622a52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PHD</td>\n",
       "      <td>2012</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2011</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2019</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1  Bachelors         2013       Pune            1   28  Female          No   \n",
       "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3    Masters         2016  Bangalore            3   27    Male          No   \n",
       "4    Masters         2017       Pune            3   24    Male         Yes   \n",
       "5        PHD         2012  New Delhi            2   41  Female          No   \n",
       "6  Bachelors         2015  Bangalore            3   29    Male         Yes   \n",
       "7    Masters         2018       Pune            3   26    Male          No   \n",
       "8    Masters         2011  Bangalore            1   35  Female          No   \n",
       "9  Bachelors         2019  New Delhi            2   32    Male         Yes   \n",
       "\n",
       "   ExperienceInCurrentDomain  \n",
       "0                          0  \n",
       "1                          3  \n",
       "2                          2  \n",
       "3                          5  \n",
       "4                          2  \n",
       "5                          6  \n",
       "6                          4  \n",
       "7                          1  \n",
       "8                          7  \n",
       "9                          2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_deploy = {\n",
    "    'Education': ['Bachelors', 'Bachelors', 'Bachelors', 'Masters', 'Masters',\n",
    "                  'PHD', 'Bachelors', 'Masters', 'Masters', 'Bachelors'],\n",
    "    'JoiningYear': [2017, 2013, 2014, 2016, 2017,\n",
    "                    2012, 2015, 2018, 2011, 2019],\n",
    "    'City': ['Bangalore', 'Pune', 'New Delhi', 'Bangalore', 'Pune',\n",
    "             'New Delhi', 'Bangalore', 'Pune', 'Bangalore', 'New Delhi'],\n",
    "    'PaymentTier': [3, 1, 3, 3, 3,\n",
    "                    2, 3, 3, 1, 2],\n",
    "    'Age': [34, 28, 38, 27, 24,\n",
    "            41, 29, 26, 35, 32],\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Male',\n",
    "               'Female', 'Male', 'Male', 'Female', 'Male'],\n",
    "    'EverBenched': ['No', 'No', 'No', 'No', 'Yes',\n",
    "                    'No', 'Yes', 'No', 'No', 'Yes'],\n",
    "    'ExperienceInCurrentDomain': [0, 3, 2, 5, 2,\n",
    "                                  6, 4, 1, 7, 2]\n",
    "}\n",
    "\n",
    "employee_deploy = pd.DataFrame(data_deploy)\n",
    "employee_deploy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e5fff6b-2a44-485d-99f7-2a3a25628242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.20000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.65832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.843274</td>\n",
       "      <td>5.541761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.250926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.25000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.50000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Education  JoiningYear       City  PaymentTier        Age Gender  \\\n",
       "count          10     10.00000         10    10.000000  10.000000     10   \n",
       "unique          3          NaN          3          NaN        NaN      2   \n",
       "top     Bachelors          NaN  Bangalore          NaN        NaN   Male   \n",
       "freq            5          NaN          4          NaN        NaN      6   \n",
       "mean          NaN   2015.20000        NaN     2.400000  31.400000    NaN   \n",
       "std           NaN      2.65832        NaN     0.843274   5.541761    NaN   \n",
       "min           NaN   2011.00000        NaN     1.000000  24.000000    NaN   \n",
       "25%           NaN   2013.25000        NaN     2.000000  27.250000    NaN   \n",
       "50%           NaN   2015.50000        NaN     3.000000  30.500000    NaN   \n",
       "75%           NaN   2017.00000        NaN     3.000000  34.750000    NaN   \n",
       "max           NaN   2019.00000        NaN     3.000000  41.000000    NaN   \n",
       "\n",
       "       EverBenched  ExperienceInCurrentDomain  \n",
       "count           10                  10.000000  \n",
       "unique           2                        NaN  \n",
       "top             No                        NaN  \n",
       "freq             7                        NaN  \n",
       "mean           NaN                   3.200000  \n",
       "std            NaN                   2.250926  \n",
       "min            NaN                   0.000000  \n",
       "25%            NaN                   2.000000  \n",
       "50%            NaN                   2.500000  \n",
       "75%            NaN                   4.750000  \n",
       "max            NaN                   7.000000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_deploy.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "861fb32f-075f-4208-b225-f4907ed308d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education                    0\n",
       "JoiningYear                  0\n",
       "City                         0\n",
       "PaymentTier                  0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "EverBenched                  0\n",
       "ExperienceInCurrentDomain    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_deploy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6808dd26-5828-4b3f-8012-54bf15e9a73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_Bangalore</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_No</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  \\\n",
       "0         2017            3   34                          0   \n",
       "1         2013            1   28                          3   \n",
       "2         2014            3   38                          2   \n",
       "3         2016            3   27                          5   \n",
       "4         2017            3   24                          2   \n",
       "5         2012            2   41                          6   \n",
       "6         2015            3   29                          4   \n",
       "7         2018            3   26                          1   \n",
       "8         2011            1   35                          7   \n",
       "9         2019            2   32                          2   \n",
       "\n",
       "   Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore  \\\n",
       "0                    1                  0              0               1   \n",
       "1                    1                  0              0               0   \n",
       "2                    1                  0              0               0   \n",
       "3                    0                  1              0               1   \n",
       "4                    0                  1              0               0   \n",
       "5                    0                  0              1               0   \n",
       "6                    1                  0              0               1   \n",
       "7                    0                  1              0               0   \n",
       "8                    0                  1              0               1   \n",
       "9                    1                  0              0               0   \n",
       "\n",
       "   City_New Delhi  City_Pune  Gender_Female  Gender_Male  EverBenched_No  \\\n",
       "0               0          0              0            1               1   \n",
       "1               0          1              1            0               1   \n",
       "2               1          0              1            0               1   \n",
       "3               0          0              0            1               1   \n",
       "4               0          1              0            1               0   \n",
       "5               1          0              1            0               1   \n",
       "6               0          0              0            1               0   \n",
       "7               0          1              0            1               1   \n",
       "8               0          0              1            0               1   \n",
       "9               1          0              0            1               0   \n",
       "\n",
       "   EverBenched_Yes  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                1  \n",
       "5                0  \n",
       "6                1  \n",
       "7                0  \n",
       "8                0  \n",
       "9                1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_deploy1 = pd.get_dummies(employee_deploy,dtype=int)\n",
    "\n",
    "employee_deploy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "202aba29-dc95-4976-aece-b7abb55625cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_Bangalore</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_No</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.713746</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.494543</td>\n",
       "      <td>-1.498537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.872357</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-0.646710</td>\n",
       "      <td>-0.093659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.475831</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.255379</td>\n",
       "      <td>-0.561951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.317221</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.836919</td>\n",
       "      <td>0.842927</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.713746</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.407546</td>\n",
       "      <td>-0.561951</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>-1.527525</td>\n",
       "      <td>1.527525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.268883</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.826006</td>\n",
       "      <td>1.311220</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.079305</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.456502</td>\n",
       "      <td>0.374634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>-1.527525</td>\n",
       "      <td>1.527525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.110272</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.027128</td>\n",
       "      <td>-1.030244</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.665408</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>0.684752</td>\n",
       "      <td>1.779513</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>0.654654</td>\n",
       "      <td>-0.654654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.506798</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.114125</td>\n",
       "      <td>-0.561951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>-0.654654</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>-1.527525</td>\n",
       "      <td>1.527525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JoiningYear  PaymentTier       Age  ExperienceInCurrentDomain  \\\n",
       "0     0.713746         0.75  0.494543                  -1.498537   \n",
       "1    -0.872357        -1.75 -0.646710                  -0.093659   \n",
       "2    -0.475831         0.75  1.255379                  -0.561951   \n",
       "3     0.317221         0.75 -0.836919                   0.842927   \n",
       "4     0.713746         0.75 -1.407546                  -0.561951   \n",
       "5    -1.268883        -0.50  1.826006                   1.311220   \n",
       "6    -0.079305         0.75 -0.456502                   0.374634   \n",
       "7     1.110272         0.75 -1.027128                  -1.030244   \n",
       "8    -1.665408        -1.75  0.684752                   1.779513   \n",
       "9     1.506798        -0.50  0.114125                  -0.561951   \n",
       "\n",
       "   Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore  \\\n",
       "0                  1.0          -0.816497      -0.333333        1.224745   \n",
       "1                  1.0          -0.816497      -0.333333       -0.816497   \n",
       "2                  1.0          -0.816497      -0.333333       -0.816497   \n",
       "3                 -1.0           1.224745      -0.333333        1.224745   \n",
       "4                 -1.0           1.224745      -0.333333       -0.816497   \n",
       "5                 -1.0          -0.816497       3.000000       -0.816497   \n",
       "6                  1.0          -0.816497      -0.333333        1.224745   \n",
       "7                 -1.0           1.224745      -0.333333       -0.816497   \n",
       "8                 -1.0           1.224745      -0.333333        1.224745   \n",
       "9                  1.0          -0.816497      -0.333333       -0.816497   \n",
       "\n",
       "   City_New Delhi  City_Pune  Gender_Female  Gender_Male  EverBenched_No  \\\n",
       "0       -0.654654  -0.654654      -0.816497     0.816497        0.654654   \n",
       "1       -0.654654   1.527525       1.224745    -1.224745        0.654654   \n",
       "2        1.527525  -0.654654       1.224745    -1.224745        0.654654   \n",
       "3       -0.654654  -0.654654      -0.816497     0.816497        0.654654   \n",
       "4       -0.654654   1.527525      -0.816497     0.816497       -1.527525   \n",
       "5        1.527525  -0.654654       1.224745    -1.224745        0.654654   \n",
       "6       -0.654654  -0.654654      -0.816497     0.816497       -1.527525   \n",
       "7       -0.654654   1.527525      -0.816497     0.816497        0.654654   \n",
       "8       -0.654654  -0.654654       1.224745    -1.224745        0.654654   \n",
       "9        1.527525  -0.654654      -0.816497     0.816497       -1.527525   \n",
       "\n",
       "   EverBenched_Yes  \n",
       "0        -0.654654  \n",
       "1        -0.654654  \n",
       "2        -0.654654  \n",
       "3        -0.654654  \n",
       "4         1.527525  \n",
       "5        -0.654654  \n",
       "6         1.527525  \n",
       "7        -0.654654  \n",
       "8        -0.654654  \n",
       "9         1.527525  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(employee_deploy1)\n",
    "\n",
    "scaled = scaler.transform(employee_deploy1)\n",
    "\n",
    "df_test_scaled = pd.DataFrame(scaled, columns=employee_deploy1.columns)\n",
    "\n",
    "df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68cfc99d-f751-4a54-b2a2-e85aac9621cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['JoiningYear', 'PaymentTier', 'Age', 'ExperienceInCurrentDomain',\n",
       "       'Education_Masters', 'Education_PHD', 'City_New Delhi', 'City_Pune',\n",
       "       'Gender_Male', 'EverBenched_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "725c6053-7d94-456b-8853-a4af1cd95ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scaled= df_test_scaled[['JoiningYear', 'PaymentTier', 'Age', 'ExperienceInCurrentDomain',\n",
    "       'Education_Masters', 'Education_PHD', 'City_New Delhi', 'City_Pune',\n",
    "       'Gender_Male', 'EverBenched_Yes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70ddba6a-e0d7-46b4-a22f-c457b4b4477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>predicted_LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>0.820474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.515983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PHD</td>\n",
       "      <td>2012</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>0.163099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.152826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2011</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>0.972061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2019</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.555262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1  Bachelors         2013       Pune            1   28  Female          No   \n",
       "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3    Masters         2016  Bangalore            3   27    Male          No   \n",
       "4    Masters         2017       Pune            3   24    Male         Yes   \n",
       "5        PHD         2012  New Delhi            2   41  Female          No   \n",
       "6  Bachelors         2015  Bangalore            3   29    Male         Yes   \n",
       "7    Masters         2018       Pune            3   26    Male          No   \n",
       "8    Masters         2011  Bangalore            1   35  Female          No   \n",
       "9  Bachelors         2019  New Delhi            2   32    Male         Yes   \n",
       "\n",
       "   ExperienceInCurrentDomain  predicted_LeaveOrNot  \n",
       "0                          0              0.153726  \n",
       "1                          3              0.999983  \n",
       "2                          2              0.076762  \n",
       "3                          5              0.820474  \n",
       "4                          2              0.515983  \n",
       "5                          6              0.163099  \n",
       "6                          4              0.152826  \n",
       "7                          1              0.980184  \n",
       "8                          7              0.972061  \n",
       "9                          2              0.555262  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_deploy['predicted_LeaveOrNot'] = best_model.predict(df_test_scaled)\n",
    "\n",
    "\n",
    "employee_deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a80d20-88d3-43c2-9acf-1a26877e60a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
